{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1form_topFeatures.ipynb","provenance":[{"file_id":"1P_UM-98DwymA_tUsjuTNGThcon_muhDz","timestamp":1612502941470}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTTlW5qNJesJ","executionInfo":{"status":"ok","timestamp":1645568827139,"user_tz":300,"elapsed":16663,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"db770f52-a023-4363-9abc-0c861914b800"},"source":["from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sklearn\n","\n","sklearn.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"F0Z-I8mWFpse","executionInfo":{"status":"ok","timestamp":1645568827989,"user_tz":300,"elapsed":856,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"8ddc31b9-53c2-4e1e-95a0-e0429bc47c62"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.0.2'"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["!pip install six"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qkZU0iJSDhf-","executionInfo":{"status":"ok","timestamp":1645568837102,"user_tz":300,"elapsed":9126,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"fb17be2b-03a6-40a4-e7e3-04278b3a3111"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (1.15.0)\n"]}]},{"cell_type":"code","source":["import six\n","import sys\n","sys.modules['sklearn.externals.six'] = six"],"metadata":{"id":"RqIsZmglGxBG","executionInfo":{"status":"ok","timestamp":1645568837325,"user_tz":300,"elapsed":237,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKc6J7e3IBmO","executionInfo":{"status":"ok","timestamp":1645568871395,"user_tz":300,"elapsed":34076,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"source":["import pandas as pd\n","data_orig = pd.read_excel('drive/My Drive/Colab Notebooks/WisconsinDataset/Forms_cleaned.xlsx', 'form1')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqkkKYzDJtJ4","colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"status":"ok","timestamp":1645568871590,"user_tz":300,"elapsed":218,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"353881ae-2df3-4070-8f11-da45f729c719"},"source":["data_orig.tail()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-02981737-313b-43d6-acef-19a658edf588\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EID</th>\n","      <th>FormID</th>\n","      <th>Flagged</th>\n","      <th>Attempt</th>\n","      <th>tot_time</th>\n","      <th>iresp.1</th>\n","      <th>iresp.2</th>\n","      <th>iresp.3</th>\n","      <th>iresp.4</th>\n","      <th>iresp.5</th>\n","      <th>iresp.6</th>\n","      <th>iresp.7</th>\n","      <th>iresp.8</th>\n","      <th>iresp.9</th>\n","      <th>iresp.10</th>\n","      <th>iresp.11</th>\n","      <th>iresp.12</th>\n","      <th>iresp.13</th>\n","      <th>iresp.14</th>\n","      <th>iresp.15</th>\n","      <th>iresp.16</th>\n","      <th>iresp.17</th>\n","      <th>iresp.18</th>\n","      <th>iresp.19</th>\n","      <th>iresp.20</th>\n","      <th>iresp.21</th>\n","      <th>iresp.22</th>\n","      <th>iresp.23</th>\n","      <th>iresp.24</th>\n","      <th>iresp.25</th>\n","      <th>iresp.26</th>\n","      <th>iresp.27</th>\n","      <th>iresp.28</th>\n","      <th>iresp.29</th>\n","      <th>iresp.30</th>\n","      <th>iresp.31</th>\n","      <th>iresp.32</th>\n","      <th>iresp.33</th>\n","      <th>iresp.34</th>\n","      <th>iresp.35</th>\n","      <th>...</th>\n","      <th>idur.131</th>\n","      <th>idur.132</th>\n","      <th>idur.133</th>\n","      <th>idur.134</th>\n","      <th>idur.135</th>\n","      <th>idur.136</th>\n","      <th>idur.137</th>\n","      <th>idur.138</th>\n","      <th>idur.139</th>\n","      <th>idur.140</th>\n","      <th>idur.141</th>\n","      <th>idur.142</th>\n","      <th>idur.143</th>\n","      <th>idur.144</th>\n","      <th>idur.145</th>\n","      <th>idur.146</th>\n","      <th>idur.147</th>\n","      <th>idur.148</th>\n","      <th>idur.149</th>\n","      <th>idur.150</th>\n","      <th>idur.151</th>\n","      <th>idur.152</th>\n","      <th>idur.153</th>\n","      <th>idur.154</th>\n","      <th>idur.155</th>\n","      <th>idur.156</th>\n","      <th>idur.157</th>\n","      <th>idur.158</th>\n","      <th>idur.159</th>\n","      <th>idur.160</th>\n","      <th>idur.161</th>\n","      <th>idur.162</th>\n","      <th>idur.163</th>\n","      <th>idur.164</th>\n","      <th>idur.165</th>\n","      <th>idur.166</th>\n","      <th>idur.167</th>\n","      <th>idur.168</th>\n","      <th>idur.169</th>\n","      <th>idur.170</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1631</th>\n","      <td>e101632</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>8760</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>43</td>\n","      <td>59</td>\n","      <td>61</td>\n","      <td>70</td>\n","      <td>24</td>\n","      <td>67</td>\n","      <td>46</td>\n","      <td>41</td>\n","      <td>86</td>\n","      <td>47</td>\n","      <td>54</td>\n","      <td>24</td>\n","      <td>46</td>\n","      <td>36</td>\n","      <td>68</td>\n","      <td>39</td>\n","      <td>66</td>\n","      <td>33</td>\n","      <td>34</td>\n","      <td>13</td>\n","      <td>38</td>\n","      <td>35</td>\n","      <td>37</td>\n","      <td>23</td>\n","      <td>64</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>72</td>\n","      <td>63</td>\n","      <td>15</td>\n","      <td>10</td>\n","      <td>72</td>\n","      <td>40</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>52</td>\n","      <td>56</td>\n","      <td>47</td>\n","      <td>61</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>1632</th>\n","      <td>e101633</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10568</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>62</td>\n","      <td>42</td>\n","      <td>22</td>\n","      <td>26</td>\n","      <td>35</td>\n","      <td>44</td>\n","      <td>69</td>\n","      <td>69</td>\n","      <td>92</td>\n","      <td>79</td>\n","      <td>79</td>\n","      <td>18</td>\n","      <td>17</td>\n","      <td>48</td>\n","      <td>230</td>\n","      <td>58</td>\n","      <td>44</td>\n","      <td>90</td>\n","      <td>60</td>\n","      <td>18</td>\n","      <td>74</td>\n","      <td>49</td>\n","      <td>149</td>\n","      <td>14</td>\n","      <td>28</td>\n","      <td>38</td>\n","      <td>27</td>\n","      <td>128</td>\n","      <td>52</td>\n","      <td>8</td>\n","      <td>11</td>\n","      <td>116</td>\n","      <td>45</td>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>116</td>\n","      <td>79</td>\n","      <td>59</td>\n","      <td>48</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>1633</th>\n","      <td>e101634</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>12449</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>165</td>\n","      <td>31</td>\n","      <td>52</td>\n","      <td>35</td>\n","      <td>27</td>\n","      <td>80</td>\n","      <td>47</td>\n","      <td>59</td>\n","      <td>78</td>\n","      <td>90</td>\n","      <td>137</td>\n","      <td>42</td>\n","      <td>35</td>\n","      <td>35</td>\n","      <td>52</td>\n","      <td>109</td>\n","      <td>75</td>\n","      <td>114</td>\n","      <td>36</td>\n","      <td>33</td>\n","      <td>34</td>\n","      <td>168</td>\n","      <td>62</td>\n","      <td>68</td>\n","      <td>44</td>\n","      <td>18</td>\n","      <td>36</td>\n","      <td>144</td>\n","      <td>98</td>\n","      <td>11</td>\n","      <td>47</td>\n","      <td>164</td>\n","      <td>28</td>\n","      <td>11</td>\n","      <td>30</td>\n","      <td>54</td>\n","      <td>19</td>\n","      <td>27</td>\n","      <td>43</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>1634</th>\n","      <td>e101635</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>8209</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>42</td>\n","      <td>36</td>\n","      <td>12</td>\n","      <td>33</td>\n","      <td>26</td>\n","      <td>57</td>\n","      <td>49</td>\n","      <td>38</td>\n","      <td>123</td>\n","      <td>39</td>\n","      <td>90</td>\n","      <td>13</td>\n","      <td>41</td>\n","      <td>38</td>\n","      <td>17</td>\n","      <td>36</td>\n","      <td>41</td>\n","      <td>30</td>\n","      <td>26</td>\n","      <td>32</td>\n","      <td>50</td>\n","      <td>18</td>\n","      <td>69</td>\n","      <td>45</td>\n","      <td>30</td>\n","      <td>24</td>\n","      <td>27</td>\n","      <td>50</td>\n","      <td>24</td>\n","      <td>43</td>\n","      <td>14</td>\n","      <td>45</td>\n","      <td>32</td>\n","      <td>14</td>\n","      <td>28</td>\n","      <td>17</td>\n","      <td>18</td>\n","      <td>109</td>\n","      <td>94</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>1635</th>\n","      <td>e101636</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>9311</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>52</td>\n","      <td>25</td>\n","      <td>86</td>\n","      <td>72</td>\n","      <td>28</td>\n","      <td>39</td>\n","      <td>70</td>\n","      <td>62</td>\n","      <td>156</td>\n","      <td>45</td>\n","      <td>36</td>\n","      <td>22</td>\n","      <td>24</td>\n","      <td>34</td>\n","      <td>14</td>\n","      <td>30</td>\n","      <td>72</td>\n","      <td>18</td>\n","      <td>44</td>\n","      <td>17</td>\n","      <td>61</td>\n","      <td>14</td>\n","      <td>61</td>\n","      <td>23</td>\n","      <td>46</td>\n","      <td>21</td>\n","      <td>35</td>\n","      <td>61</td>\n","      <td>38</td>\n","      <td>14</td>\n","      <td>12</td>\n","      <td>61</td>\n","      <td>45</td>\n","      <td>13</td>\n","      <td>14</td>\n","      <td>62</td>\n","      <td>28</td>\n","      <td>51</td>\n","      <td>45</td>\n","      <td>46</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 515 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02981737-313b-43d6-acef-19a658edf588')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-02981737-313b-43d6-acef-19a658edf588 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-02981737-313b-43d6-acef-19a658edf588');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          EID FormID  Flagged  Attempt  ...  idur.167  idur.168  idur.169  idur.170\n","1631  e101632  form1        0        1  ...        56        47        61        19\n","1632  e101633  form1        0        1  ...        79        59        48        40\n","1633  e101634  form1        0        1  ...        19        27        43        14\n","1634  e101635  form1        0        1  ...        18       109        94        14\n","1635  e101636  form1        0        1  ...        28        51        45        46\n","\n","[5 rows x 515 columns]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"SbnaQxJMJ4zo","colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"status":"ok","timestamp":1645568872027,"user_tz":300,"elapsed":264,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"fd52c176-ce76-45f3-e0e5-5e4bdd8fa8f7"},"source":["data_final = data_orig\n","data_final"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-7f247889-7537-439c-8171-380e1a61060b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EID</th>\n","      <th>FormID</th>\n","      <th>Flagged</th>\n","      <th>Attempt</th>\n","      <th>tot_time</th>\n","      <th>iresp.1</th>\n","      <th>iresp.2</th>\n","      <th>iresp.3</th>\n","      <th>iresp.4</th>\n","      <th>iresp.5</th>\n","      <th>iresp.6</th>\n","      <th>iresp.7</th>\n","      <th>iresp.8</th>\n","      <th>iresp.9</th>\n","      <th>iresp.10</th>\n","      <th>iresp.11</th>\n","      <th>iresp.12</th>\n","      <th>iresp.13</th>\n","      <th>iresp.14</th>\n","      <th>iresp.15</th>\n","      <th>iresp.16</th>\n","      <th>iresp.17</th>\n","      <th>iresp.18</th>\n","      <th>iresp.19</th>\n","      <th>iresp.20</th>\n","      <th>iresp.21</th>\n","      <th>iresp.22</th>\n","      <th>iresp.23</th>\n","      <th>iresp.24</th>\n","      <th>iresp.25</th>\n","      <th>iresp.26</th>\n","      <th>iresp.27</th>\n","      <th>iresp.28</th>\n","      <th>iresp.29</th>\n","      <th>iresp.30</th>\n","      <th>iresp.31</th>\n","      <th>iresp.32</th>\n","      <th>iresp.33</th>\n","      <th>iresp.34</th>\n","      <th>iresp.35</th>\n","      <th>...</th>\n","      <th>idur.131</th>\n","      <th>idur.132</th>\n","      <th>idur.133</th>\n","      <th>idur.134</th>\n","      <th>idur.135</th>\n","      <th>idur.136</th>\n","      <th>idur.137</th>\n","      <th>idur.138</th>\n","      <th>idur.139</th>\n","      <th>idur.140</th>\n","      <th>idur.141</th>\n","      <th>idur.142</th>\n","      <th>idur.143</th>\n","      <th>idur.144</th>\n","      <th>idur.145</th>\n","      <th>idur.146</th>\n","      <th>idur.147</th>\n","      <th>idur.148</th>\n","      <th>idur.149</th>\n","      <th>idur.150</th>\n","      <th>idur.151</th>\n","      <th>idur.152</th>\n","      <th>idur.153</th>\n","      <th>idur.154</th>\n","      <th>idur.155</th>\n","      <th>idur.156</th>\n","      <th>idur.157</th>\n","      <th>idur.158</th>\n","      <th>idur.159</th>\n","      <th>idur.160</th>\n","      <th>idur.161</th>\n","      <th>idur.162</th>\n","      <th>idur.163</th>\n","      <th>idur.164</th>\n","      <th>idur.165</th>\n","      <th>idur.166</th>\n","      <th>idur.167</th>\n","      <th>idur.168</th>\n","      <th>idur.169</th>\n","      <th>idur.170</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>e100001</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>10133</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>85</td>\n","      <td>47</td>\n","      <td>60</td>\n","      <td>46</td>\n","      <td>98</td>\n","      <td>106</td>\n","      <td>92</td>\n","      <td>63</td>\n","      <td>103</td>\n","      <td>48</td>\n","      <td>42</td>\n","      <td>66</td>\n","      <td>26</td>\n","      <td>57</td>\n","      <td>14</td>\n","      <td>63</td>\n","      <td>45</td>\n","      <td>28</td>\n","      <td>21</td>\n","      <td>15</td>\n","      <td>64</td>\n","      <td>23</td>\n","      <td>61</td>\n","      <td>28</td>\n","      <td>35</td>\n","      <td>28</td>\n","      <td>64</td>\n","      <td>122</td>\n","      <td>20</td>\n","      <td>18</td>\n","      <td>17</td>\n","      <td>102</td>\n","      <td>55</td>\n","      <td>50</td>\n","      <td>17</td>\n","      <td>28</td>\n","      <td>53</td>\n","      <td>82</td>\n","      <td>100</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>e100002</td>\n","      <td>form1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12409</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>191</td>\n","      <td>48</td>\n","      <td>52</td>\n","      <td>108</td>\n","      <td>69</td>\n","      <td>59</td>\n","      <td>93</td>\n","      <td>133</td>\n","      <td>136</td>\n","      <td>94</td>\n","      <td>139</td>\n","      <td>43</td>\n","      <td>23</td>\n","      <td>82</td>\n","      <td>56</td>\n","      <td>32</td>\n","      <td>77</td>\n","      <td>87</td>\n","      <td>75</td>\n","      <td>34</td>\n","      <td>98</td>\n","      <td>30</td>\n","      <td>107</td>\n","      <td>42</td>\n","      <td>126</td>\n","      <td>31</td>\n","      <td>47</td>\n","      <td>51</td>\n","      <td>83</td>\n","      <td>64</td>\n","      <td>22</td>\n","      <td>121</td>\n","      <td>114</td>\n","      <td>44</td>\n","      <td>36</td>\n","      <td>53</td>\n","      <td>120</td>\n","      <td>93</td>\n","      <td>87</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>e100003</td>\n","      <td>form1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12457</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>62</td>\n","      <td>54</td>\n","      <td>89</td>\n","      <td>72</td>\n","      <td>68</td>\n","      <td>78</td>\n","      <td>77</td>\n","      <td>77</td>\n","      <td>170</td>\n","      <td>48</td>\n","      <td>84</td>\n","      <td>62</td>\n","      <td>52</td>\n","      <td>122</td>\n","      <td>41</td>\n","      <td>98</td>\n","      <td>38</td>\n","      <td>49</td>\n","      <td>52</td>\n","      <td>27</td>\n","      <td>62</td>\n","      <td>18</td>\n","      <td>78</td>\n","      <td>47</td>\n","      <td>109</td>\n","      <td>47</td>\n","      <td>44</td>\n","      <td>72</td>\n","      <td>23</td>\n","      <td>16</td>\n","      <td>73</td>\n","      <td>34</td>\n","      <td>92</td>\n","      <td>83</td>\n","      <td>50</td>\n","      <td>30</td>\n","      <td>63</td>\n","      <td>96</td>\n","      <td>79</td>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>e100004</td>\n","      <td>form1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>11389</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>79</td>\n","      <td>69</td>\n","      <td>105</td>\n","      <td>75</td>\n","      <td>60</td>\n","      <td>64</td>\n","      <td>77</td>\n","      <td>54</td>\n","      <td>73</td>\n","      <td>50</td>\n","      <td>60</td>\n","      <td>29</td>\n","      <td>37</td>\n","      <td>72</td>\n","      <td>34</td>\n","      <td>78</td>\n","      <td>74</td>\n","      <td>93</td>\n","      <td>59</td>\n","      <td>39</td>\n","      <td>39</td>\n","      <td>30</td>\n","      <td>34</td>\n","      <td>35</td>\n","      <td>62</td>\n","      <td>33</td>\n","      <td>47</td>\n","      <td>87</td>\n","      <td>83</td>\n","      <td>45</td>\n","      <td>30</td>\n","      <td>93</td>\n","      <td>49</td>\n","      <td>26</td>\n","      <td>57</td>\n","      <td>41</td>\n","      <td>59</td>\n","      <td>41</td>\n","      <td>84</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>e100005</td>\n","      <td>form1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>13669</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>171</td>\n","      <td>29</td>\n","      <td>92</td>\n","      <td>56</td>\n","      <td>55</td>\n","      <td>189</td>\n","      <td>146</td>\n","      <td>108</td>\n","      <td>151</td>\n","      <td>71</td>\n","      <td>57</td>\n","      <td>31</td>\n","      <td>33</td>\n","      <td>138</td>\n","      <td>131</td>\n","      <td>92</td>\n","      <td>110</td>\n","      <td>30</td>\n","      <td>57</td>\n","      <td>20</td>\n","      <td>34</td>\n","      <td>34</td>\n","      <td>72</td>\n","      <td>56</td>\n","      <td>96</td>\n","      <td>46</td>\n","      <td>119</td>\n","      <td>66</td>\n","      <td>133</td>\n","      <td>34</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>58</td>\n","      <td>127</td>\n","      <td>63</td>\n","      <td>68</td>\n","      <td>164</td>\n","      <td>74</td>\n","      <td>63</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1631</th>\n","      <td>e101632</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>8760</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>43</td>\n","      <td>59</td>\n","      <td>61</td>\n","      <td>70</td>\n","      <td>24</td>\n","      <td>67</td>\n","      <td>46</td>\n","      <td>41</td>\n","      <td>86</td>\n","      <td>47</td>\n","      <td>54</td>\n","      <td>24</td>\n","      <td>46</td>\n","      <td>36</td>\n","      <td>68</td>\n","      <td>39</td>\n","      <td>66</td>\n","      <td>33</td>\n","      <td>34</td>\n","      <td>13</td>\n","      <td>38</td>\n","      <td>35</td>\n","      <td>37</td>\n","      <td>23</td>\n","      <td>64</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>72</td>\n","      <td>63</td>\n","      <td>15</td>\n","      <td>10</td>\n","      <td>72</td>\n","      <td>40</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>52</td>\n","      <td>56</td>\n","      <td>47</td>\n","      <td>61</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>1632</th>\n","      <td>e101633</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10568</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>62</td>\n","      <td>42</td>\n","      <td>22</td>\n","      <td>26</td>\n","      <td>35</td>\n","      <td>44</td>\n","      <td>69</td>\n","      <td>69</td>\n","      <td>92</td>\n","      <td>79</td>\n","      <td>79</td>\n","      <td>18</td>\n","      <td>17</td>\n","      <td>48</td>\n","      <td>230</td>\n","      <td>58</td>\n","      <td>44</td>\n","      <td>90</td>\n","      <td>60</td>\n","      <td>18</td>\n","      <td>74</td>\n","      <td>49</td>\n","      <td>149</td>\n","      <td>14</td>\n","      <td>28</td>\n","      <td>38</td>\n","      <td>27</td>\n","      <td>128</td>\n","      <td>52</td>\n","      <td>8</td>\n","      <td>11</td>\n","      <td>116</td>\n","      <td>45</td>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>116</td>\n","      <td>79</td>\n","      <td>59</td>\n","      <td>48</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>1633</th>\n","      <td>e101634</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>12449</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>165</td>\n","      <td>31</td>\n","      <td>52</td>\n","      <td>35</td>\n","      <td>27</td>\n","      <td>80</td>\n","      <td>47</td>\n","      <td>59</td>\n","      <td>78</td>\n","      <td>90</td>\n","      <td>137</td>\n","      <td>42</td>\n","      <td>35</td>\n","      <td>35</td>\n","      <td>52</td>\n","      <td>109</td>\n","      <td>75</td>\n","      <td>114</td>\n","      <td>36</td>\n","      <td>33</td>\n","      <td>34</td>\n","      <td>168</td>\n","      <td>62</td>\n","      <td>68</td>\n","      <td>44</td>\n","      <td>18</td>\n","      <td>36</td>\n","      <td>144</td>\n","      <td>98</td>\n","      <td>11</td>\n","      <td>47</td>\n","      <td>164</td>\n","      <td>28</td>\n","      <td>11</td>\n","      <td>30</td>\n","      <td>54</td>\n","      <td>19</td>\n","      <td>27</td>\n","      <td>43</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>1634</th>\n","      <td>e101635</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>8209</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>42</td>\n","      <td>36</td>\n","      <td>12</td>\n","      <td>33</td>\n","      <td>26</td>\n","      <td>57</td>\n","      <td>49</td>\n","      <td>38</td>\n","      <td>123</td>\n","      <td>39</td>\n","      <td>90</td>\n","      <td>13</td>\n","      <td>41</td>\n","      <td>38</td>\n","      <td>17</td>\n","      <td>36</td>\n","      <td>41</td>\n","      <td>30</td>\n","      <td>26</td>\n","      <td>32</td>\n","      <td>50</td>\n","      <td>18</td>\n","      <td>69</td>\n","      <td>45</td>\n","      <td>30</td>\n","      <td>24</td>\n","      <td>27</td>\n","      <td>50</td>\n","      <td>24</td>\n","      <td>43</td>\n","      <td>14</td>\n","      <td>45</td>\n","      <td>32</td>\n","      <td>14</td>\n","      <td>28</td>\n","      <td>17</td>\n","      <td>18</td>\n","      <td>109</td>\n","      <td>94</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>1635</th>\n","      <td>e101636</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>9311</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>52</td>\n","      <td>25</td>\n","      <td>86</td>\n","      <td>72</td>\n","      <td>28</td>\n","      <td>39</td>\n","      <td>70</td>\n","      <td>62</td>\n","      <td>156</td>\n","      <td>45</td>\n","      <td>36</td>\n","      <td>22</td>\n","      <td>24</td>\n","      <td>34</td>\n","      <td>14</td>\n","      <td>30</td>\n","      <td>72</td>\n","      <td>18</td>\n","      <td>44</td>\n","      <td>17</td>\n","      <td>61</td>\n","      <td>14</td>\n","      <td>61</td>\n","      <td>23</td>\n","      <td>46</td>\n","      <td>21</td>\n","      <td>35</td>\n","      <td>61</td>\n","      <td>38</td>\n","      <td>14</td>\n","      <td>12</td>\n","      <td>61</td>\n","      <td>45</td>\n","      <td>13</td>\n","      <td>14</td>\n","      <td>62</td>\n","      <td>28</td>\n","      <td>51</td>\n","      <td>45</td>\n","      <td>46</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1636 rows × 515 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f247889-7537-439c-8171-380e1a61060b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7f247889-7537-439c-8171-380e1a61060b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7f247889-7537-439c-8171-380e1a61060b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          EID FormID  Flagged  Attempt  ...  idur.167  idur.168  idur.169  idur.170\n","0     e100001  form1        0        5  ...        53        82       100        21\n","1     e100002  form1        1        1  ...       120        93        87        29\n","2     e100003  form1        1        1  ...        63        96        79        48\n","3     e100004  form1        1        3  ...        59        41        84        17\n","4     e100005  form1        1        5  ...       164        74        63        17\n","...       ...    ...      ...      ...  ...       ...       ...       ...       ...\n","1631  e101632  form1        0        1  ...        56        47        61        19\n","1632  e101633  form1        0        1  ...        79        59        48        40\n","1633  e101634  form1        0        1  ...        19        27        43        14\n","1634  e101635  form1        0        1  ...        18       109        94        14\n","1635  e101636  form1        0        1  ...        28        51        45        46\n","\n","[1636 rows x 515 columns]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"TaDQ4E-pLXq_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645568872027,"user_tz":300,"elapsed":12,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"3c0d1045-8b1f-4d7c-f2b5-2cb93020e350"},"source":["print(data_final.isnull().sum())\n","print(data_final.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["EID         0\n","FormID      0\n","Flagged     0\n","Attempt     0\n","tot_time    0\n","           ..\n","idur.166    0\n","idur.167    0\n","idur.168    0\n","idur.169    0\n","idur.170    0\n","Length: 515, dtype: int64\n","(1636, 515)\n"]}]},{"cell_type":"code","metadata":{"id":"yy8CdE2Jol-u","colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"status":"ok","timestamp":1645568872178,"user_tz":300,"elapsed":160,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"6a1087d2-9f04-4c08-95d0-15e7c73c75d6"},"source":["##### time #####\n","data_final['mean_idur'] = data_final.loc[:, 'idur.1':'idur.170'].mean(axis=1)\n","data_final['median_idur'] = data_final.loc[:, 'idur.1':'idur.170'].median(axis=1)\n","data_final['max_idur'] = data_final.loc[:, 'idur.1':'idur.170'].max(axis=1)\n","data_final['min_idur'] = data_final.loc[:, 'idur.1':'idur.170'].min(axis=1)\n","\n","#### correct answers####\n","data_final['iraw_score'] = data_final.loc[:, 'iraw.1':'iraw.170'].sum(axis=1)\n","data_final['iraw_score_pct'] = data_final['iraw_score']/170\n","data_final"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-d3543cf1-bef4-4149-93c4-828c464c1260\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EID</th>\n","      <th>FormID</th>\n","      <th>Flagged</th>\n","      <th>Attempt</th>\n","      <th>tot_time</th>\n","      <th>iresp.1</th>\n","      <th>iresp.2</th>\n","      <th>iresp.3</th>\n","      <th>iresp.4</th>\n","      <th>iresp.5</th>\n","      <th>iresp.6</th>\n","      <th>iresp.7</th>\n","      <th>iresp.8</th>\n","      <th>iresp.9</th>\n","      <th>iresp.10</th>\n","      <th>iresp.11</th>\n","      <th>iresp.12</th>\n","      <th>iresp.13</th>\n","      <th>iresp.14</th>\n","      <th>iresp.15</th>\n","      <th>iresp.16</th>\n","      <th>iresp.17</th>\n","      <th>iresp.18</th>\n","      <th>iresp.19</th>\n","      <th>iresp.20</th>\n","      <th>iresp.21</th>\n","      <th>iresp.22</th>\n","      <th>iresp.23</th>\n","      <th>iresp.24</th>\n","      <th>iresp.25</th>\n","      <th>iresp.26</th>\n","      <th>iresp.27</th>\n","      <th>iresp.28</th>\n","      <th>iresp.29</th>\n","      <th>iresp.30</th>\n","      <th>iresp.31</th>\n","      <th>iresp.32</th>\n","      <th>iresp.33</th>\n","      <th>iresp.34</th>\n","      <th>iresp.35</th>\n","      <th>...</th>\n","      <th>idur.137</th>\n","      <th>idur.138</th>\n","      <th>idur.139</th>\n","      <th>idur.140</th>\n","      <th>idur.141</th>\n","      <th>idur.142</th>\n","      <th>idur.143</th>\n","      <th>idur.144</th>\n","      <th>idur.145</th>\n","      <th>idur.146</th>\n","      <th>idur.147</th>\n","      <th>idur.148</th>\n","      <th>idur.149</th>\n","      <th>idur.150</th>\n","      <th>idur.151</th>\n","      <th>idur.152</th>\n","      <th>idur.153</th>\n","      <th>idur.154</th>\n","      <th>idur.155</th>\n","      <th>idur.156</th>\n","      <th>idur.157</th>\n","      <th>idur.158</th>\n","      <th>idur.159</th>\n","      <th>idur.160</th>\n","      <th>idur.161</th>\n","      <th>idur.162</th>\n","      <th>idur.163</th>\n","      <th>idur.164</th>\n","      <th>idur.165</th>\n","      <th>idur.166</th>\n","      <th>idur.167</th>\n","      <th>idur.168</th>\n","      <th>idur.169</th>\n","      <th>idur.170</th>\n","      <th>mean_idur</th>\n","      <th>median_idur</th>\n","      <th>max_idur</th>\n","      <th>min_idur</th>\n","      <th>iraw_score</th>\n","      <th>iraw_score_pct</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>e100001</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>10133</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>92</td>\n","      <td>63</td>\n","      <td>103</td>\n","      <td>48</td>\n","      <td>42</td>\n","      <td>66</td>\n","      <td>26</td>\n","      <td>57</td>\n","      <td>14</td>\n","      <td>63</td>\n","      <td>45</td>\n","      <td>28</td>\n","      <td>21</td>\n","      <td>15</td>\n","      <td>64</td>\n","      <td>23</td>\n","      <td>61</td>\n","      <td>28</td>\n","      <td>35</td>\n","      <td>28</td>\n","      <td>64</td>\n","      <td>122</td>\n","      <td>20</td>\n","      <td>18</td>\n","      <td>17</td>\n","      <td>102</td>\n","      <td>55</td>\n","      <td>50</td>\n","      <td>17</td>\n","      <td>28</td>\n","      <td>53</td>\n","      <td>82</td>\n","      <td>100</td>\n","      <td>21</td>\n","      <td>56.323529</td>\n","      <td>50.0</td>\n","      <td>143</td>\n","      <td>14</td>\n","      <td>54</td>\n","      <td>0.317647</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>e100002</td>\n","      <td>form1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12409</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>93</td>\n","      <td>133</td>\n","      <td>136</td>\n","      <td>94</td>\n","      <td>139</td>\n","      <td>43</td>\n","      <td>23</td>\n","      <td>82</td>\n","      <td>56</td>\n","      <td>32</td>\n","      <td>77</td>\n","      <td>87</td>\n","      <td>75</td>\n","      <td>34</td>\n","      <td>98</td>\n","      <td>30</td>\n","      <td>107</td>\n","      <td>42</td>\n","      <td>126</td>\n","      <td>31</td>\n","      <td>47</td>\n","      <td>51</td>\n","      <td>83</td>\n","      <td>64</td>\n","      <td>22</td>\n","      <td>121</td>\n","      <td>114</td>\n","      <td>44</td>\n","      <td>36</td>\n","      <td>53</td>\n","      <td>120</td>\n","      <td>93</td>\n","      <td>87</td>\n","      <td>29</td>\n","      <td>69.158824</td>\n","      <td>63.0</td>\n","      <td>202</td>\n","      <td>11</td>\n","      <td>55</td>\n","      <td>0.323529</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>e100003</td>\n","      <td>form1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12457</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>77</td>\n","      <td>77</td>\n","      <td>170</td>\n","      <td>48</td>\n","      <td>84</td>\n","      <td>62</td>\n","      <td>52</td>\n","      <td>122</td>\n","      <td>41</td>\n","      <td>98</td>\n","      <td>38</td>\n","      <td>49</td>\n","      <td>52</td>\n","      <td>27</td>\n","      <td>62</td>\n","      <td>18</td>\n","      <td>78</td>\n","      <td>47</td>\n","      <td>109</td>\n","      <td>47</td>\n","      <td>44</td>\n","      <td>72</td>\n","      <td>23</td>\n","      <td>16</td>\n","      <td>73</td>\n","      <td>34</td>\n","      <td>92</td>\n","      <td>83</td>\n","      <td>50</td>\n","      <td>30</td>\n","      <td>63</td>\n","      <td>96</td>\n","      <td>79</td>\n","      <td>48</td>\n","      <td>69.547059</td>\n","      <td>65.5</td>\n","      <td>179</td>\n","      <td>16</td>\n","      <td>61</td>\n","      <td>0.358824</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>e100004</td>\n","      <td>form1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>11389</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>2.0</td>\n","      <td>2</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>77</td>\n","      <td>54</td>\n","      <td>73</td>\n","      <td>50</td>\n","      <td>60</td>\n","      <td>29</td>\n","      <td>37</td>\n","      <td>72</td>\n","      <td>34</td>\n","      <td>78</td>\n","      <td>74</td>\n","      <td>93</td>\n","      <td>59</td>\n","      <td>39</td>\n","      <td>39</td>\n","      <td>30</td>\n","      <td>34</td>\n","      <td>35</td>\n","      <td>62</td>\n","      <td>33</td>\n","      <td>47</td>\n","      <td>87</td>\n","      <td>83</td>\n","      <td>45</td>\n","      <td>30</td>\n","      <td>93</td>\n","      <td>49</td>\n","      <td>26</td>\n","      <td>57</td>\n","      <td>41</td>\n","      <td>59</td>\n","      <td>41</td>\n","      <td>84</td>\n","      <td>17</td>\n","      <td>62.882353</td>\n","      <td>62.0</td>\n","      <td>154</td>\n","      <td>12</td>\n","      <td>61</td>\n","      <td>0.358824</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>e100005</td>\n","      <td>form1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>13669</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>146</td>\n","      <td>108</td>\n","      <td>151</td>\n","      <td>71</td>\n","      <td>57</td>\n","      <td>31</td>\n","      <td>33</td>\n","      <td>138</td>\n","      <td>131</td>\n","      <td>92</td>\n","      <td>110</td>\n","      <td>30</td>\n","      <td>57</td>\n","      <td>20</td>\n","      <td>34</td>\n","      <td>34</td>\n","      <td>72</td>\n","      <td>56</td>\n","      <td>96</td>\n","      <td>46</td>\n","      <td>119</td>\n","      <td>66</td>\n","      <td>133</td>\n","      <td>34</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>58</td>\n","      <td>127</td>\n","      <td>63</td>\n","      <td>68</td>\n","      <td>164</td>\n","      <td>74</td>\n","      <td>63</td>\n","      <td>17</td>\n","      <td>76.547059</td>\n","      <td>69.0</td>\n","      <td>189</td>\n","      <td>0</td>\n","      <td>62</td>\n","      <td>0.364706</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1631</th>\n","      <td>e101632</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>8760</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>46</td>\n","      <td>41</td>\n","      <td>86</td>\n","      <td>47</td>\n","      <td>54</td>\n","      <td>24</td>\n","      <td>46</td>\n","      <td>36</td>\n","      <td>68</td>\n","      <td>39</td>\n","      <td>66</td>\n","      <td>33</td>\n","      <td>34</td>\n","      <td>13</td>\n","      <td>38</td>\n","      <td>35</td>\n","      <td>37</td>\n","      <td>23</td>\n","      <td>64</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>72</td>\n","      <td>63</td>\n","      <td>15</td>\n","      <td>10</td>\n","      <td>72</td>\n","      <td>40</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>52</td>\n","      <td>56</td>\n","      <td>47</td>\n","      <td>61</td>\n","      <td>19</td>\n","      <td>48.658824</td>\n","      <td>43.0</td>\n","      <td>152</td>\n","      <td>8</td>\n","      <td>156</td>\n","      <td>0.917647</td>\n","    </tr>\n","    <tr>\n","      <th>1632</th>\n","      <td>e101633</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10568</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>69</td>\n","      <td>69</td>\n","      <td>92</td>\n","      <td>79</td>\n","      <td>79</td>\n","      <td>18</td>\n","      <td>17</td>\n","      <td>48</td>\n","      <td>230</td>\n","      <td>58</td>\n","      <td>44</td>\n","      <td>90</td>\n","      <td>60</td>\n","      <td>18</td>\n","      <td>74</td>\n","      <td>49</td>\n","      <td>149</td>\n","      <td>14</td>\n","      <td>28</td>\n","      <td>38</td>\n","      <td>27</td>\n","      <td>128</td>\n","      <td>52</td>\n","      <td>8</td>\n","      <td>11</td>\n","      <td>116</td>\n","      <td>45</td>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>116</td>\n","      <td>79</td>\n","      <td>59</td>\n","      <td>48</td>\n","      <td>40</td>\n","      <td>59.335294</td>\n","      <td>49.0</td>\n","      <td>230</td>\n","      <td>7</td>\n","      <td>153</td>\n","      <td>0.900000</td>\n","    </tr>\n","    <tr>\n","      <th>1633</th>\n","      <td>e101634</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>12449</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>47</td>\n","      <td>59</td>\n","      <td>78</td>\n","      <td>90</td>\n","      <td>137</td>\n","      <td>42</td>\n","      <td>35</td>\n","      <td>35</td>\n","      <td>52</td>\n","      <td>109</td>\n","      <td>75</td>\n","      <td>114</td>\n","      <td>36</td>\n","      <td>33</td>\n","      <td>34</td>\n","      <td>168</td>\n","      <td>62</td>\n","      <td>68</td>\n","      <td>44</td>\n","      <td>18</td>\n","      <td>36</td>\n","      <td>144</td>\n","      <td>98</td>\n","      <td>11</td>\n","      <td>47</td>\n","      <td>164</td>\n","      <td>28</td>\n","      <td>11</td>\n","      <td>30</td>\n","      <td>54</td>\n","      <td>19</td>\n","      <td>27</td>\n","      <td>43</td>\n","      <td>14</td>\n","      <td>69.894118</td>\n","      <td>47.0</td>\n","      <td>322</td>\n","      <td>7</td>\n","      <td>154</td>\n","      <td>0.905882</td>\n","    </tr>\n","    <tr>\n","      <th>1634</th>\n","      <td>e101635</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>8209</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>49</td>\n","      <td>38</td>\n","      <td>123</td>\n","      <td>39</td>\n","      <td>90</td>\n","      <td>13</td>\n","      <td>41</td>\n","      <td>38</td>\n","      <td>17</td>\n","      <td>36</td>\n","      <td>41</td>\n","      <td>30</td>\n","      <td>26</td>\n","      <td>32</td>\n","      <td>50</td>\n","      <td>18</td>\n","      <td>69</td>\n","      <td>45</td>\n","      <td>30</td>\n","      <td>24</td>\n","      <td>27</td>\n","      <td>50</td>\n","      <td>24</td>\n","      <td>43</td>\n","      <td>14</td>\n","      <td>45</td>\n","      <td>32</td>\n","      <td>14</td>\n","      <td>28</td>\n","      <td>17</td>\n","      <td>18</td>\n","      <td>109</td>\n","      <td>94</td>\n","      <td>14</td>\n","      <td>45.376471</td>\n","      <td>34.0</td>\n","      <td>258</td>\n","      <td>10</td>\n","      <td>152</td>\n","      <td>0.894118</td>\n","    </tr>\n","    <tr>\n","      <th>1635</th>\n","      <td>e101636</td>\n","      <td>form1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>9311</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>70</td>\n","      <td>62</td>\n","      <td>156</td>\n","      <td>45</td>\n","      <td>36</td>\n","      <td>22</td>\n","      <td>24</td>\n","      <td>34</td>\n","      <td>14</td>\n","      <td>30</td>\n","      <td>72</td>\n","      <td>18</td>\n","      <td>44</td>\n","      <td>17</td>\n","      <td>61</td>\n","      <td>14</td>\n","      <td>61</td>\n","      <td>23</td>\n","      <td>46</td>\n","      <td>21</td>\n","      <td>35</td>\n","      <td>61</td>\n","      <td>38</td>\n","      <td>14</td>\n","      <td>12</td>\n","      <td>61</td>\n","      <td>45</td>\n","      <td>13</td>\n","      <td>14</td>\n","      <td>62</td>\n","      <td>28</td>\n","      <td>51</td>\n","      <td>45</td>\n","      <td>46</td>\n","      <td>51.547059</td>\n","      <td>45.0</td>\n","      <td>201</td>\n","      <td>10</td>\n","      <td>156</td>\n","      <td>0.917647</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1636 rows × 521 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3543cf1-bef4-4149-93c4-828c464c1260')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d3543cf1-bef4-4149-93c4-828c464c1260 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d3543cf1-bef4-4149-93c4-828c464c1260');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          EID FormID  Flagged  ...  min_idur  iraw_score  iraw_score_pct\n","0     e100001  form1        0  ...        14          54        0.317647\n","1     e100002  form1        1  ...        11          55        0.323529\n","2     e100003  form1        1  ...        16          61        0.358824\n","3     e100004  form1        1  ...        12          61        0.358824\n","4     e100005  form1        1  ...         0          62        0.364706\n","...       ...    ...      ...  ...       ...         ...             ...\n","1631  e101632  form1        0  ...         8         156        0.917647\n","1632  e101633  form1        0  ...         7         153        0.900000\n","1633  e101634  form1        0  ...         7         154        0.905882\n","1634  e101635  form1        0  ...        10         152        0.894118\n","1635  e101636  form1        0  ...        10         156        0.917647\n","\n","[1636 rows x 521 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["data_final.fillna(data_final.mean(), inplace=True)"],"metadata":{"id":"MH2-1RQpaxkD","executionInfo":{"status":"ok","timestamp":1645568872383,"user_tz":300,"elapsed":214,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"802f536d-48c0-4f1f-f39e-35fd86cfac1e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}]},{"cell_type":"code","metadata":{"id":"ghubyPkw1cCu","executionInfo":{"status":"ok","timestamp":1645568872384,"user_tz":300,"elapsed":23,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"source":["######## iraw_idur_OEF (both+OEF) #############\n","col_features = ['Attempt', 'tot_time', 'mean_idur', 'median_idur', 'max_idur', 'min_idur', 'iraw_score_pct']\n","\n","for x in range(1,171):\n","  col_features.append('idur.'+str(x))\n","\n","for i in range(1,171):\n","  col_features.append('iraw.'+str(i))\n","\n","X = data_final.loc[:, col_features]\n","Y = data_final.Flagged    "],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V1mHZIMSBvIi"},"source":["**End of Dataset Features selection!**"]},{"cell_type":"code","metadata":{"id":"0dk0S7S9Cztn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645568872385,"user_tz":300,"elapsed":23,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"ff7b7dd1-66ea-4cc7-c558-f48e68644259"},"source":["from collections import Counter\n","from matplotlib import pyplot\n","from numpy import where\n","counter = Counter(Y)\n","print(counter)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({0: 1590, 1: 46})\n"]}]},{"cell_type":"code","metadata":{"id":"XSseujJPAyST","executionInfo":{"status":"ok","timestamp":1645568872592,"user_tz":300,"elapsed":223,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","X_scaled = scaler.fit_transform(X)"],"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Import Libraries\n","from sklearn.preprocessing import MinMaxScaler\n","num_cols = X.columns\n","\n","# apply standardization on numerical features\n","for i in num_cols:\n","    # fit on training data column\n","    scale = MinMaxScaler(feature_range=(0, 1)).fit(X[[i]])\n","\n","    # transform the training data column\n","    X[i] = scale.transform(X[[i]])\n","    \n","print(\"\\n\\nTraining Features After Scaling: \")\n","print(\"=================================\\n\")\n","X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":574},"id":"kI5lCYftp-6V","executionInfo":{"status":"ok","timestamp":1645568877169,"user_tz":300,"elapsed":4581,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"a6516a25-ee1f-4317-950d-8cc48a9a7485"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Training Features After Scaling: \n","=================================\n","\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-81b596be-187f-48e9-8652-6855e6841def\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Attempt</th>\n","      <th>tot_time</th>\n","      <th>mean_idur</th>\n","      <th>median_idur</th>\n","      <th>max_idur</th>\n","      <th>min_idur</th>\n","      <th>iraw_score_pct</th>\n","      <th>idur.1</th>\n","      <th>idur.2</th>\n","      <th>idur.3</th>\n","      <th>idur.4</th>\n","      <th>idur.5</th>\n","      <th>idur.6</th>\n","      <th>idur.7</th>\n","      <th>idur.8</th>\n","      <th>idur.9</th>\n","      <th>idur.10</th>\n","      <th>idur.11</th>\n","      <th>idur.12</th>\n","      <th>idur.13</th>\n","      <th>idur.14</th>\n","      <th>idur.15</th>\n","      <th>idur.16</th>\n","      <th>idur.17</th>\n","      <th>idur.18</th>\n","      <th>idur.19</th>\n","      <th>idur.20</th>\n","      <th>idur.21</th>\n","      <th>idur.22</th>\n","      <th>idur.23</th>\n","      <th>idur.24</th>\n","      <th>idur.25</th>\n","      <th>idur.26</th>\n","      <th>idur.27</th>\n","      <th>idur.28</th>\n","      <th>idur.29</th>\n","      <th>idur.30</th>\n","      <th>idur.31</th>\n","      <th>idur.32</th>\n","      <th>idur.33</th>\n","      <th>...</th>\n","      <th>iraw.131</th>\n","      <th>iraw.132</th>\n","      <th>iraw.133</th>\n","      <th>iraw.134</th>\n","      <th>iraw.135</th>\n","      <th>iraw.136</th>\n","      <th>iraw.137</th>\n","      <th>iraw.138</th>\n","      <th>iraw.139</th>\n","      <th>iraw.140</th>\n","      <th>iraw.141</th>\n","      <th>iraw.142</th>\n","      <th>iraw.143</th>\n","      <th>iraw.144</th>\n","      <th>iraw.145</th>\n","      <th>iraw.146</th>\n","      <th>iraw.147</th>\n","      <th>iraw.148</th>\n","      <th>iraw.149</th>\n","      <th>iraw.150</th>\n","      <th>iraw.151</th>\n","      <th>iraw.152</th>\n","      <th>iraw.153</th>\n","      <th>iraw.154</th>\n","      <th>iraw.155</th>\n","      <th>iraw.156</th>\n","      <th>iraw.157</th>\n","      <th>iraw.158</th>\n","      <th>iraw.159</th>\n","      <th>iraw.160</th>\n","      <th>iraw.161</th>\n","      <th>iraw.162</th>\n","      <th>iraw.163</th>\n","      <th>iraw.164</th>\n","      <th>iraw.165</th>\n","      <th>iraw.166</th>\n","      <th>iraw.167</th>\n","      <th>iraw.168</th>\n","      <th>iraw.169</th>\n","      <th>iraw.170</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>0.251140</td>\n","      <td>0.254294</td>\n","      <td>0.246154</td>\n","      <td>0.037668</td>\n","      <td>0.482759</td>\n","      <td>0.000000</td>\n","      <td>0.169065</td>\n","      <td>0.041812</td>\n","      <td>0.114007</td>\n","      <td>0.066667</td>\n","      <td>0.057377</td>\n","      <td>0.126761</td>\n","      <td>0.146814</td>\n","      <td>0.323276</td>\n","      <td>0.144886</td>\n","      <td>0.232092</td>\n","      <td>0.100649</td>\n","      <td>0.136253</td>\n","      <td>0.032258</td>\n","      <td>0.181661</td>\n","      <td>0.133820</td>\n","      <td>0.119741</td>\n","      <td>0.076754</td>\n","      <td>0.113065</td>\n","      <td>0.114286</td>\n","      <td>0.077647</td>\n","      <td>0.180812</td>\n","      <td>0.227074</td>\n","      <td>0.040541</td>\n","      <td>0.087935</td>\n","      <td>0.491597</td>\n","      <td>0.380645</td>\n","      <td>0.139319</td>\n","      <td>0.131673</td>\n","      <td>0.270916</td>\n","      <td>0.119741</td>\n","      <td>0.173034</td>\n","      <td>0.305556</td>\n","      <td>0.059809</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.2</td>\n","      <td>0.373250</td>\n","      <td>0.379208</td>\n","      <td>0.379487</td>\n","      <td>0.090583</td>\n","      <td>0.379310</td>\n","      <td>0.009804</td>\n","      <td>0.151079</td>\n","      <td>0.081882</td>\n","      <td>0.250814</td>\n","      <td>0.112121</td>\n","      <td>0.196721</td>\n","      <td>0.161972</td>\n","      <td>0.119114</td>\n","      <td>0.366379</td>\n","      <td>0.051136</td>\n","      <td>0.372493</td>\n","      <td>0.152597</td>\n","      <td>0.131387</td>\n","      <td>0.039427</td>\n","      <td>0.129758</td>\n","      <td>0.216545</td>\n","      <td>0.165049</td>\n","      <td>0.096491</td>\n","      <td>0.218593</td>\n","      <td>0.354286</td>\n","      <td>0.070588</td>\n","      <td>0.154982</td>\n","      <td>0.048035</td>\n","      <td>0.139640</td>\n","      <td>0.077710</td>\n","      <td>0.256303</td>\n","      <td>0.206452</td>\n","      <td>0.123839</td>\n","      <td>0.206406</td>\n","      <td>0.338645</td>\n","      <td>0.116505</td>\n","      <td>0.215730</td>\n","      <td>0.166667</td>\n","      <td>0.028708</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.2</td>\n","      <td>0.375825</td>\n","      <td>0.382986</td>\n","      <td>0.405128</td>\n","      <td>0.069955</td>\n","      <td>0.551724</td>\n","      <td>0.068627</td>\n","      <td>0.201439</td>\n","      <td>0.055749</td>\n","      <td>0.179153</td>\n","      <td>0.042424</td>\n","      <td>0.200820</td>\n","      <td>0.373239</td>\n","      <td>0.077562</td>\n","      <td>0.512931</td>\n","      <td>0.113636</td>\n","      <td>0.146132</td>\n","      <td>0.113636</td>\n","      <td>0.243309</td>\n","      <td>0.093190</td>\n","      <td>0.110727</td>\n","      <td>0.094891</td>\n","      <td>0.271845</td>\n","      <td>0.140351</td>\n","      <td>0.236181</td>\n","      <td>0.297143</td>\n","      <td>0.298824</td>\n","      <td>0.313653</td>\n","      <td>0.144105</td>\n","      <td>0.162162</td>\n","      <td>0.153374</td>\n","      <td>0.474790</td>\n","      <td>0.296774</td>\n","      <td>0.266254</td>\n","      <td>0.459075</td>\n","      <td>0.362550</td>\n","      <td>0.391586</td>\n","      <td>0.242697</td>\n","      <td>0.229167</td>\n","      <td>0.155502</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.6</td>\n","      <td>0.318526</td>\n","      <td>0.318125</td>\n","      <td>0.369231</td>\n","      <td>0.047534</td>\n","      <td>0.413793</td>\n","      <td>0.068627</td>\n","      <td>0.219424</td>\n","      <td>0.247387</td>\n","      <td>0.153094</td>\n","      <td>0.112121</td>\n","      <td>0.262295</td>\n","      <td>0.246479</td>\n","      <td>0.041551</td>\n","      <td>0.228448</td>\n","      <td>0.238636</td>\n","      <td>0.257880</td>\n","      <td>0.074675</td>\n","      <td>0.218978</td>\n","      <td>0.189964</td>\n","      <td>0.171280</td>\n","      <td>0.199513</td>\n","      <td>0.171521</td>\n","      <td>0.028509</td>\n","      <td>0.125628</td>\n","      <td>0.234286</td>\n","      <td>0.171765</td>\n","      <td>0.184502</td>\n","      <td>0.056769</td>\n","      <td>0.056306</td>\n","      <td>0.094070</td>\n","      <td>0.285714</td>\n","      <td>0.212903</td>\n","      <td>0.191950</td>\n","      <td>0.309609</td>\n","      <td>0.155378</td>\n","      <td>0.077670</td>\n","      <td>0.146067</td>\n","      <td>0.166667</td>\n","      <td>0.105263</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.440850</td>\n","      <td>0.451111</td>\n","      <td>0.441026</td>\n","      <td>0.078924</td>\n","      <td>0.000000</td>\n","      <td>0.078431</td>\n","      <td>0.406475</td>\n","      <td>0.139373</td>\n","      <td>0.250814</td>\n","      <td>0.178788</td>\n","      <td>0.258197</td>\n","      <td>0.193662</td>\n","      <td>0.152355</td>\n","      <td>0.155172</td>\n","      <td>0.485795</td>\n","      <td>0.303725</td>\n","      <td>0.116883</td>\n","      <td>0.000000</td>\n","      <td>0.462366</td>\n","      <td>0.057093</td>\n","      <td>0.211679</td>\n","      <td>0.239482</td>\n","      <td>0.162281</td>\n","      <td>0.228643</td>\n","      <td>0.914286</td>\n","      <td>0.211765</td>\n","      <td>0.143911</td>\n","      <td>0.183406</td>\n","      <td>0.322072</td>\n","      <td>0.051125</td>\n","      <td>0.285714</td>\n","      <td>0.258065</td>\n","      <td>0.000000</td>\n","      <td>0.252669</td>\n","      <td>0.474104</td>\n","      <td>0.000000</td>\n","      <td>0.076404</td>\n","      <td>0.531250</td>\n","      <td>0.086124</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1631</th>\n","      <td>0.2</td>\n","      <td>0.177477</td>\n","      <td>0.179700</td>\n","      <td>0.174359</td>\n","      <td>0.045740</td>\n","      <td>0.275862</td>\n","      <td>1.000000</td>\n","      <td>0.118705</td>\n","      <td>0.073171</td>\n","      <td>0.120521</td>\n","      <td>0.339394</td>\n","      <td>0.241803</td>\n","      <td>0.154930</td>\n","      <td>0.052632</td>\n","      <td>0.056034</td>\n","      <td>0.039773</td>\n","      <td>0.203438</td>\n","      <td>0.050325</td>\n","      <td>0.133820</td>\n","      <td>0.050179</td>\n","      <td>0.044983</td>\n","      <td>0.077859</td>\n","      <td>0.090615</td>\n","      <td>0.052632</td>\n","      <td>0.213568</td>\n","      <td>0.171429</td>\n","      <td>0.265882</td>\n","      <td>0.129151</td>\n","      <td>0.034934</td>\n","      <td>0.094595</td>\n","      <td>0.110429</td>\n","      <td>0.138655</td>\n","      <td>0.148387</td>\n","      <td>0.436533</td>\n","      <td>0.081851</td>\n","      <td>0.131474</td>\n","      <td>0.093851</td>\n","      <td>0.051685</td>\n","      <td>0.326389</td>\n","      <td>0.066986</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1632</th>\n","      <td>0.2</td>\n","      <td>0.274478</td>\n","      <td>0.283604</td>\n","      <td>0.235897</td>\n","      <td>0.115695</td>\n","      <td>0.241379</td>\n","      <td>0.970588</td>\n","      <td>0.064748</td>\n","      <td>0.170732</td>\n","      <td>0.127036</td>\n","      <td>0.045455</td>\n","      <td>0.315574</td>\n","      <td>0.197183</td>\n","      <td>0.041551</td>\n","      <td>0.172414</td>\n","      <td>0.235795</td>\n","      <td>0.189112</td>\n","      <td>0.224026</td>\n","      <td>0.121655</td>\n","      <td>0.118280</td>\n","      <td>0.145329</td>\n","      <td>0.192214</td>\n","      <td>0.074434</td>\n","      <td>0.072368</td>\n","      <td>0.190955</td>\n","      <td>0.120000</td>\n","      <td>0.077647</td>\n","      <td>0.398524</td>\n","      <td>0.030568</td>\n","      <td>0.063063</td>\n","      <td>0.053170</td>\n","      <td>0.134454</td>\n","      <td>0.154839</td>\n","      <td>0.139319</td>\n","      <td>0.081851</td>\n","      <td>0.095618</td>\n","      <td>0.320388</td>\n","      <td>0.238202</td>\n","      <td>0.222222</td>\n","      <td>0.023923</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1633</th>\n","      <td>0.2</td>\n","      <td>0.375396</td>\n","      <td>0.386364</td>\n","      <td>0.215385</td>\n","      <td>0.198206</td>\n","      <td>0.241379</td>\n","      <td>0.980392</td>\n","      <td>0.107914</td>\n","      <td>0.134146</td>\n","      <td>0.293160</td>\n","      <td>0.100000</td>\n","      <td>0.475410</td>\n","      <td>0.077465</td>\n","      <td>0.141274</td>\n","      <td>0.491379</td>\n","      <td>0.517045</td>\n","      <td>0.083095</td>\n","      <td>0.303571</td>\n","      <td>0.411192</td>\n","      <td>0.326165</td>\n","      <td>0.036332</td>\n","      <td>0.416058</td>\n","      <td>0.064725</td>\n","      <td>0.017544</td>\n","      <td>0.045226</td>\n","      <td>0.045714</td>\n","      <td>0.265882</td>\n","      <td>0.214022</td>\n","      <td>0.030568</td>\n","      <td>0.128378</td>\n","      <td>0.000000</td>\n","      <td>0.159664</td>\n","      <td>0.296774</td>\n","      <td>0.068111</td>\n","      <td>0.249110</td>\n","      <td>0.231076</td>\n","      <td>0.022654</td>\n","      <td>0.366292</td>\n","      <td>0.083333</td>\n","      <td>0.124402</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1634</th>\n","      <td>0.2</td>\n","      <td>0.147916</td>\n","      <td>0.147756</td>\n","      <td>0.082051</td>\n","      <td>0.140807</td>\n","      <td>0.344828</td>\n","      <td>0.960784</td>\n","      <td>0.025180</td>\n","      <td>0.151568</td>\n","      <td>0.166124</td>\n","      <td>0.115152</td>\n","      <td>0.049180</td>\n","      <td>0.066901</td>\n","      <td>0.132964</td>\n","      <td>0.146552</td>\n","      <td>0.125000</td>\n","      <td>0.048711</td>\n","      <td>0.105519</td>\n","      <td>0.236010</td>\n","      <td>0.039427</td>\n","      <td>0.053633</td>\n","      <td>0.306569</td>\n","      <td>0.103560</td>\n","      <td>0.092105</td>\n","      <td>0.065327</td>\n","      <td>0.108571</td>\n","      <td>0.171765</td>\n","      <td>0.088561</td>\n","      <td>0.043668</td>\n","      <td>0.031532</td>\n","      <td>0.020450</td>\n","      <td>0.176471</td>\n","      <td>0.096774</td>\n","      <td>0.055728</td>\n","      <td>0.131673</td>\n","      <td>0.099602</td>\n","      <td>0.058252</td>\n","      <td>0.051685</td>\n","      <td>0.041667</td>\n","      <td>0.045455</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1635</th>\n","      <td>0.2</td>\n","      <td>0.207039</td>\n","      <td>0.207809</td>\n","      <td>0.194872</td>\n","      <td>0.089686</td>\n","      <td>0.344828</td>\n","      <td>1.000000</td>\n","      <td>0.190647</td>\n","      <td>0.121951</td>\n","      <td>0.153094</td>\n","      <td>0.139394</td>\n","      <td>0.151639</td>\n","      <td>0.066901</td>\n","      <td>0.166205</td>\n","      <td>0.366379</td>\n","      <td>0.252841</td>\n","      <td>0.074499</td>\n","      <td>0.107143</td>\n","      <td>0.192214</td>\n","      <td>0.258065</td>\n","      <td>0.086505</td>\n","      <td>0.255474</td>\n","      <td>0.139159</td>\n","      <td>0.028509</td>\n","      <td>0.306533</td>\n","      <td>0.011429</td>\n","      <td>0.108235</td>\n","      <td>0.191882</td>\n","      <td>0.043668</td>\n","      <td>0.063063</td>\n","      <td>0.390593</td>\n","      <td>0.126050</td>\n","      <td>0.135484</td>\n","      <td>0.080495</td>\n","      <td>0.092527</td>\n","      <td>0.139442</td>\n","      <td>0.110032</td>\n","      <td>0.116854</td>\n","      <td>0.319444</td>\n","      <td>0.105263</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1636 rows × 347 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81b596be-187f-48e9-8652-6855e6841def')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-81b596be-187f-48e9-8652-6855e6841def button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-81b596be-187f-48e9-8652-6855e6841def');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      Attempt  tot_time  mean_idur  ...  iraw.168  iraw.169  iraw.170\n","0         1.0  0.251140   0.254294  ...       1.0       0.0       0.0\n","1         0.2  0.373250   0.379208  ...       0.0       1.0       0.0\n","2         0.2  0.375825   0.382986  ...       0.0       0.0       0.0\n","3         0.6  0.318526   0.318125  ...       1.0       1.0       1.0\n","4         1.0  0.440850   0.451111  ...       0.0       0.0       1.0\n","...       ...       ...        ...  ...       ...       ...       ...\n","1631      0.2  0.177477   0.179700  ...       1.0       1.0       1.0\n","1632      0.2  0.274478   0.283604  ...       1.0       1.0       1.0\n","1633      0.2  0.375396   0.386364  ...       1.0       1.0       1.0\n","1634      0.2  0.147916   0.147756  ...       1.0       0.0       1.0\n","1635      0.2  0.207039   0.207809  ...       1.0       1.0       1.0\n","\n","[1636 rows x 347 columns]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["!pip install mlxtend  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PI7aRNzZCjo3","executionInfo":{"status":"ok","timestamp":1645568885374,"user_tz":300,"elapsed":8212,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"b5f8a188-7f21-4b9d-9e9a-ce76bf0bc732"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n","Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n","Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.3.5)\n","Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.4.0)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.0.2)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.21.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.1.0)\n"]}]},{"cell_type":"code","metadata":{"id":"_YWUyKs9bB6k","executionInfo":{"status":"ok","timestamp":1645568885560,"user_tz":300,"elapsed":198,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"source":["import numpy as np\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import cross_val_score\n","\n","from mlxtend.classifier import StackingClassifier\n","\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import FunctionTransformer"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXqtoSyBGMAt","executionInfo":{"status":"ok","timestamp":1645568886015,"user_tz":300,"elapsed":459,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"source":["from sklearn import model_selection\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCRNmgEgN484","executionInfo":{"status":"ok","timestamp":1645568886016,"user_tz":300,"elapsed":5,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"source":["\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from matplotlib import pyplot\n","from sklearn.metrics import auc\n","\n","from numpy import sqrt\n","from numpy import argmax"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wd9FhXSpQhBt","executionInfo":{"status":"ok","timestamp":1645568886266,"user_tz":300,"elapsed":255,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"source":["###### SMOTE and RandomUnderSampler (for balancing data) ############\n","\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.pipeline import Pipeline\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"dr6ZPxLnXzAa","executionInfo":{"status":"ok","timestamp":1645568886449,"user_tz":300,"elapsed":189,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"source":["import seaborn as sns\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, auc\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","import matplotlib.pyplot as plt"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"ws8wcsPBwwpK","executionInfo":{"status":"ok","timestamp":1645568886449,"user_tz":300,"elapsed":4,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"source":["import xlwt \n","from xlwt import Workbook \n","  \n","wb = Workbook() "],"execution_count":21,"outputs":[]},{"cell_type":"code","source":["\n","k_fold = model_selection.KFold(n_splits = 4, random_state=25, shuffle=True)\n","\n","full_trainset_x = np.array([])\n","full_trainset_y = np.array([])\n","full_testset_x = np.array([])\n","full_testset_y = np.array([])\n","\n","full_testset_pred1 = np.array([])\n","full_testset_pred2 = np.array([])\n","full_testset_pred3 = np.array([])\n","full_testset_pred4 = np.array([])\n","full_testset_pred5 = np.array([])\n","full_testset_pred6 = np.array([])\n","full_testset_pred7 = np.array([])\n","full_testset_pred8 = np.array([])\n","full_testset_pred9 = np.array([])\n","\n","full_testset_probs1 = np.array([])\n","full_testset_probs2 = np.array([])\n","full_testset_probs3 = np.array([])\n","full_testset_probs4 = np.array([])\n","full_testset_probs5 = np.array([])\n","full_testset_probs6 = np.array([])\n","full_testset_probs7 = np.array([])\n","full_testset_probs8 = np.array([])\n","full_testset_probs9 = np.array([])\n","\n","nosmote_probs1 = np.array([])\n","nosmote_probs2 = np.array([])\n","nosmote_probs3 = np.array([])\n","nosmote_probs4 = np.array([])\n","nosmote_probs5 = np.array([])\n","nosmote_probs6 = np.array([])\n","nosmote_probs7 = np.array([])\n","nosmote_probs8 = np.array([])\n","nosmote_probs9 = np.array([])\n","\n","nosmote_pred1 = np.array([])\n","nosmote_pred2 = np.array([])\n","nosmote_pred3 = np.array([])\n","nosmote_pred4 = np.array([])\n","nosmote_pred5 = np.array([])\n","nosmote_pred6 = np.array([])\n","nosmote_pred7 = np.array([])\n","nosmote_pred8 = np.array([])\n","nosmote_pred9 = np.array([])\n","\n","precision1_1 = np.array([])\n","recall1_1 = np.array([])\n","f1_score1_1 = np.array([])\n","kappa1_1 = np.array([])\n","roc1_1 = np.array([])\n","fpr1_1 = np.array([])\n","\n","precision1_2 = np.array([])\n","recall1_2 = np.array([])\n","f1_score1_2 = np.array([])\n","kappa1_2 = np.array([])\n","roc1_2 = np.array([])\n","fpr1_2 = np.array([])\n","\n","precision1_3 = np.array([])\n","recall1_3 = np.array([])\n","f1_score1_3 = np.array([])\n","kappa1_3 = np.array([])\n","roc1_3 = np.array([])\n","fpr1_3 = np.array([])\n","\n","precision1_4 = np.array([])\n","recall1_4 = np.array([])\n","f1_score1_4 = np.array([])\n","kappa1_4 = np.array([])\n","roc1_4 = np.array([])\n","fpr1_4 = np.array([])\n","\n","\n","precision2_1 = np.array([])\n","recall2_1 = np.array([])\n","f1_score2_1 = np.array([])\n","kappa2_1 = np.array([])\n","roc2_1 = np.array([])\n","fpr2_1 = np.array([])\n","\n","precision2_2 = np.array([])\n","recall2_2 = np.array([])\n","f1_score2_2 = np.array([])\n","kappa2_2 = np.array([])\n","roc2_2 = np.array([])\n","fpr2_2 = np.array([])\n","\n","precision2_3 = np.array([])\n","recall2_3 = np.array([])\n","f1_score2_3 = np.array([])\n","kappa2_3 = np.array([])\n","roc2_3 = np.array([])\n","fpr2_3 = np.array([])\n","\n","precision2_4 = np.array([])\n","recall2_4 = np.array([])\n","f1_score2_4 = np.array([])\n","kappa2_4 = np.array([])\n","roc2_4 = np.array([])\n","fpr2_4 = np.array([])\n","\n","\n","precision3_1 = np.array([])\n","recall3_1 = np.array([])\n","f1_score3_1 = np.array([])\n","kappa3_1 = np.array([])\n","roc3_1 = np.array([])\n","fpr3_1 = np.array([])\n","\n","precision3_2 = np.array([])\n","recall3_2 = np.array([])\n","f1_score3_2 = np.array([])\n","kappa3_2 = np.array([])\n","roc3_2 = np.array([])\n","fpr3_2 = np.array([])\n","\n","precision3_3 = np.array([])\n","recall3_3 = np.array([])\n","f1_score3_3 = np.array([])\n","kappa3_3 = np.array([])\n","roc3_3 = np.array([])\n","fpr3_3 = np.array([])\n","\n","precision3_4 = np.array([])\n","recall3_4 = np.array([])\n","f1_score3_4 = np.array([])\n","kappa3_4 = np.array([])\n","roc3_4 = np.array([])\n","fpr3_4 = np.array([])\n","\n","\n","precision4_1 = np.array([])\n","recall4_1 = np.array([])\n","f1_score4_1 = np.array([])\n","kappa4_1 = np.array([])\n","roc4_1 = np.array([])\n","fpr4_1 = np.array([])\n","\n","precision4_2 = np.array([])\n","recall4_2 = np.array([])\n","f1_score4_2 = np.array([])\n","kappa4_2 = np.array([])\n","roc4_2 = np.array([])\n","fpr4_2 = np.array([])\n","\n","precision4_3 = np.array([])\n","recall4_3 = np.array([])\n","f1_score4_3 = np.array([])\n","kappa4_3 = np.array([])\n","roc4_3 = np.array([])\n","fpr4_3 = np.array([])\n","\n","precision4_4 = np.array([])\n","recall4_4 = np.array([])\n","f1_score4_4 = np.array([])\n","kappa4_4 = np.array([])\n","roc4_4 = np.array([])\n","fpr4_4 = np.array([])\n","\n","\n","precision5_1 = np.array([])\n","recall5_1 = np.array([])\n","f1_score5_1 = np.array([])\n","kappa5_1 = np.array([])\n","roc5_1 = np.array([])\n","fpr5_1 = np.array([])\n","\n","precision5_2 = np.array([])\n","recall5_2 = np.array([])\n","f1_score5_2 = np.array([])\n","kappa5_2 = np.array([])\n","roc5_2 = np.array([])\n","fpr5_2 = np.array([])\n","\n","precision5_3 = np.array([])\n","recall5_3 = np.array([])\n","f1_score5_3 = np.array([])\n","kappa5_3 = np.array([])\n","roc5_3 = np.array([])\n","fpr5_3 = np.array([])\n","\n","precision5_4 = np.array([])\n","recall5_4 = np.array([])\n","f1_score5_4 = np.array([])\n","kappa5_4 = np.array([])\n","roc5_4 = np.array([])\n","fpr5_4 = np.array([])\n","\n","\n","precision6_1 = np.array([])\n","recall6_1 = np.array([])\n","f1_score6_1 = np.array([])\n","kappa6_1 = np.array([])\n","roc6_1 = np.array([])\n","fpr6_1 = np.array([])\n","\n","precision6_2 = np.array([])\n","recall6_2 = np.array([])\n","f1_score6_2 = np.array([])\n","kappa6_2 = np.array([])\n","roc6_2 = np.array([])\n","fpr6_2 = np.array([])\n","\n","precision6_3 = np.array([])\n","recall6_3 = np.array([])\n","f1_score6_3 = np.array([])\n","kappa6_3 = np.array([])\n","roc6_3 = np.array([])\n","fpr6_3 = np.array([])\n","\n","precision6_4 = np.array([])\n","recall6_4 = np.array([])\n","f1_score6_4 = np.array([])\n","kappa6_4 = np.array([])\n","roc6_4 = np.array([])\n","fpr6_4 = np.array([])\n","\n","\n","precision7_1 = np.array([])\n","recall7_1 = np.array([])\n","f1_score7_1 = np.array([])\n","kappa7_1 = np.array([])\n","roc7_1 = np.array([])\n","fpr7_1 = np.array([])\n","\n","precision7_2 = np.array([])\n","recall7_2 = np.array([])\n","f1_score7_2 = np.array([])\n","kappa7_2 = np.array([])\n","roc7_2 = np.array([])\n","fpr7_2 = np.array([])\n","\n","precision7_3 = np.array([])\n","recall7_3 = np.array([])\n","f1_score7_3 = np.array([])\n","kappa7_3 = np.array([])\n","roc7_3 = np.array([])\n","fpr7_3 = np.array([])\n","\n","precision7_4 = np.array([])\n","recall7_4 = np.array([])\n","f1_score7_4 = np.array([])\n","kappa7_4 = np.array([])\n","roc7_4 = np.array([])\n","fpr7_4 = np.array([])\n","\n","\n","precision8_1 = np.array([])\n","recall8_1 = np.array([])\n","f1_score8_1 = np.array([])\n","kappa8_1 = np.array([])\n","roc8_1 = np.array([])\n","fpr8_1 = np.array([])\n","\n","precision8_2 = np.array([])\n","recall8_2 = np.array([])\n","f1_score8_2 = np.array([])\n","kappa8_2 = np.array([])\n","roc8_2 = np.array([])\n","fpr8_2 = np.array([])\n","\n","precision8_3 = np.array([])\n","recall8_3 = np.array([])\n","f1_score8_3 = np.array([])\n","kappa8_3 = np.array([])\n","roc8_3 = np.array([])\n","fpr8_3 = np.array([])\n","\n","precision8_4 = np.array([])\n","recall8_4 = np.array([])\n","f1_score8_4 = np.array([])\n","kappa8_4 = np.array([])\n","roc8_4 = np.array([])\n","fpr8_4 = np.array([])\n","\n","\n","precision_s4 = np.array([])\n","recall_s4 = np.array([])\n","f1_s4 = np.array([])\n","kappa_s4 = np.array([])\n","roc_s4 = np.array([])\n","fpr_s4 = np.array([])\n","\n","precision_s3 = np.array([])\n","recall_s3 = np.array([])\n","f1_s3 = np.array([])\n","kappa_s3 = np.array([])\n","roc_s3 = np.array([])\n","fpr_s3 = np.array([])\n","\n","precision_s2 = np.array([])\n","recall_s2 = np.array([])\n","f1_s2 = np.array([])\n","kappa_s2 = np.array([])\n","roc_s2 = np.array([])\n","fpr_s2 = np.array([])\n","\n","precision_s5 = np.array([])\n","recall_s5 = np.array([])\n","f1_s5 = np.array([])\n","kappa_s5 = np.array([])\n","roc_s5 = np.array([])\n","fpr_s5 = np.array([])\n","\n","precision_s6 = np.array([])\n","recall_s6 = np.array([])\n","f1_s6 = np.array([])\n","kappa_s6 = np.array([])\n","roc_s6 = np.array([])\n","fpr_s6 = np.array([])\n","\n","precision_s7 = np.array([])\n","recall_s7 = np.array([])\n","f1_s7 = np.array([])\n","kappa_s7 = np.array([])\n","roc_s7 = np.array([])\n","fpr_s7 = np.array([])\n","\n","precision_s8 = np.array([])\n","recall_s8 = np.array([])\n","f1_s8 = np.array([])\n","kappa_s8 = np.array([])\n","roc_s8 = np.array([])\n","fpr_s8 = np.array([])"],"metadata":{"id":"H9jeBqeMa5GP","executionInfo":{"status":"ok","timestamp":1645568887800,"user_tz":300,"elapsed":1355,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["########## different feature sets #############\n","col = []    ### all ######\n","col1 = []   ### iraw_oef ######\n","col2 = []   ### idur_oef ######\n","\n","for i in range(0,347):\n","  col = np.append(col, i)\n","\n","for m in range(0,177):\n","  col2 = np.append(col2, m)\n","\n","for n in range(0,7):\n","  col1 = np.append(col1, n)\n","for l in range(177,347):\n","  col1 = np.append(col1, l)\n","\n","def feature_all(X):\n","    return X\n","\n","def feature_1(X):\n","    return X[ : , col1.astype(int)]\n","  \n","def feature_2(X):\n","    return X[ : , col2.astype(int)]\n","\n"],"metadata":{"id":"AqRni4Sna9S-","executionInfo":{"status":"ok","timestamp":1645568887800,"user_tz":300,"elapsed":6,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Import Libraries\n","from sklearn.ensemble import ExtraTreesClassifier\n","\n","model = ExtraTreesClassifier()\n","model.fit(X,Y)\n","columns = X.columns.values\n","\n","print(model.feature_importances_)\n","feat_importances = pd.Series(model.feature_importances_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4El28OLBotMu","executionInfo":{"status":"ok","timestamp":1645568888436,"user_tz":300,"elapsed":641,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"6ea53cd7-c64a-4414-a097-8fc0b1fb17c8"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.00305992 0.01715327 0.02569513 0.0129098  0.00766266 0.0061039\n"," 0.00515771 0.00312132 0.00294128 0.00366641 0.00280578 0.00159336\n"," 0.00416958 0.00388117 0.00262705 0.0034953  0.00392244 0.00416049\n"," 0.00280925 0.00526893 0.00389785 0.00387259 0.00331333 0.00345672\n"," 0.00424721 0.00395622 0.00145385 0.00320479 0.00137773 0.00400222\n"," 0.00275688 0.00319841 0.00440288 0.00388969 0.00274712 0.00312786\n"," 0.00364526 0.00247336 0.00228824 0.00258284 0.00412645 0.00444093\n"," 0.00453543 0.00312705 0.00411878 0.00482706 0.0042392  0.00419175\n"," 0.00308294 0.0017433  0.00340325 0.00258663 0.00344961 0.00256004\n"," 0.00619367 0.00526051 0.00223033 0.00256371 0.00230891 0.00244086\n"," 0.00452813 0.00350741 0.0054328  0.00324911 0.00234745 0.00353349\n"," 0.00455738 0.00188639 0.00284743 0.00239259 0.00226252 0.00394498\n"," 0.00319236 0.00458148 0.00430266 0.00351618 0.00425396 0.00485292\n"," 0.00356066 0.00117198 0.00364046 0.00250896 0.00257888 0.00513911\n"," 0.0050175  0.00322929 0.00252093 0.00393749 0.00296628 0.00327621\n"," 0.00686821 0.00245054 0.00444098 0.00453204 0.00386124 0.00330954\n"," 0.00240432 0.00251759 0.00322661 0.00797056 0.00427853 0.00267567\n"," 0.00357693 0.00493014 0.00217833 0.00382934 0.00425931 0.00279393\n"," 0.00245594 0.00256308 0.00345133 0.00292458 0.00285206 0.00398122\n"," 0.00291609 0.0031163  0.00471844 0.00543105 0.00347432 0.00369141\n"," 0.00544233 0.00451526 0.0039587  0.00283777 0.00426899 0.00298747\n"," 0.00384971 0.00224277 0.00516951 0.00383308 0.00395409 0.00254745\n"," 0.00186135 0.00374616 0.00410791 0.00217078 0.00406844 0.00365205\n"," 0.00231855 0.00389231 0.00160905 0.0036313  0.00361904 0.00289995\n"," 0.00519081 0.00373965 0.00302065 0.00151457 0.00849293 0.0042924\n"," 0.00195705 0.004064   0.00935028 0.00466741 0.003384   0.00429224\n"," 0.00273083 0.00424238 0.00242184 0.00253035 0.00361006 0.00531563\n"," 0.00328727 0.00471383 0.00446202 0.00480026 0.00113633 0.00279391\n"," 0.00557864 0.00542265 0.00014912 0.00240491 0.00350893 0.00334709\n"," 0.00504328 0.00139283 0.00404749 0.00165903 0.00039811 0.00188767\n"," 0.00198745 0.00112865 0.00176893 0.0011683  0.00142855 0.00155066\n"," 0.00146575 0.00183306 0.00185398 0.00110391 0.00072104 0.00156232\n"," 0.00222309 0.0006125  0.00155949 0.00162621 0.00192782 0.003479\n"," 0.00030899 0.000594   0.00116749 0.00245225 0.00092526 0.00312254\n"," 0.00489917 0.00108093 0.00159958 0.00084016 0.0039153  0.00239944\n"," 0.00192722 0.00289212 0.00418987 0.00058045 0.00164518 0.00089936\n"," 0.00126794 0.00047531 0.00098111 0.00107266 0.0021555  0.00408341\n"," 0.00323365 0.00034295 0.00246191 0.00227767 0.00267983 0.00098475\n"," 0.00134465 0.00175648 0.00175118 0.00279726 0.00221299 0.00396656\n"," 0.00203049 0.00225514 0.0010973  0.00206561 0.00198998 0.00183397\n"," 0.0008052  0.00197138 0.00264101 0.00195843 0.00196305 0.00192112\n"," 0.00315592 0.00182599 0.00294982 0.00406347 0.00415978 0.00135571\n"," 0.00315941 0.00096472 0.00075267 0.00051295 0.00139109 0.00061845\n"," 0.00086439 0.0022586  0.00188636 0.00123276 0.00210735 0.00188342\n"," 0.0010907  0.00161422 0.00128298 0.00150252 0.00084974 0.00265301\n"," 0.0026089  0.00219753 0.00165924 0.00256463 0.00173248 0.00455179\n"," 0.00175339 0.00146023 0.00255136 0.00145919 0.00269062 0.00274122\n"," 0.0017133  0.00149514 0.00187264 0.00110813 0.00198379 0.00134422\n"," 0.00265457 0.00157139 0.00206315 0.00225945 0.00133809 0.00148734\n"," 0.00171452 0.00118963 0.00181162 0.00073063 0.00559384 0.00104298\n"," 0.00147654 0.00195309 0.00138762 0.00136607 0.00205847 0.00021889\n"," 0.00269069 0.0015115  0.00062851 0.00067839 0.00081651 0.0021894\n"," 0.00227485 0.00228279 0.00148115 0.00181287 0.00245015 0.00170388\n"," 0.00157926 0.00325173 0.00167101 0.00105717 0.00296805 0.00193537\n"," 0.00192704 0.00084093 0.00239419 0.00137856 0.00343074 0.00233307\n"," 0.00066801 0.0015002  0.00243427 0.00758715 0.00185785 0.00112118\n"," 0.00049231 0.00103646 0.00176173 0.00163549 0.00066525 0.00135118\n"," 0.00157327 0.0015905  0.00248729 0.00106578 0.00154284]\n"]}]},{"cell_type":"code","source":["# Print 10 Best Features\n","\n","top = feat_importances.nlargest(10)\n","feature = top.index\n","names = columns[feature]\n","\n","top_features = pd.DataFrame()\n","top_features[\"Features\"]=names\n","top_features[\"    Score\"]=top.values\n","top_features[\"Ranking\"] = [\"       --->      Rank-01\",\"       --->      Rank-02\",\"       --->      Rank-03\",\"       --->      Rank-04\",\"       --->      Rank-05\",\"       --->      Rank-06\",\"       --->      Rank-07\",\"       --->      Rank-08\",\"       --->      Rank-09\",\"       --->      Rank-10\"]\n","print(\"\\n===================================================\\n\")\n","print(\"================== TOP 10 FEATURES ================\")\n","print(\"\\n===================================================\\n\")\n","print(top_features.to_string(index=False))\n","print(\"\\n===================================================\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cvicJKAjpBbe","executionInfo":{"status":"ok","timestamp":1645568888606,"user_tz":300,"elapsed":17,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"22cbf9b0-c2c0-4707-f1d8-f35237776d72"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===================================================\n","\n","================== TOP 10 FEATURES ================\n","\n","===================================================\n","\n","   Features      Score                  Ranking\n","  mean_idur   0.025695        --->      Rank-01\n","   tot_time   0.017153        --->      Rank-02\n","median_idur   0.012910        --->      Rank-03\n","   idur.146   0.009350        --->      Rank-04\n","   idur.142   0.008493        --->      Rank-05\n","    idur.93   0.007971        --->      Rank-06\n","   max_idur   0.007663        --->      Rank-07\n","   iraw.157   0.007587        --->      Rank-08\n","    idur.84   0.006868        --->      Rank-09\n","    idur.48   0.006194        --->      Rank-10\n","\n","===================================================\n","\n"]}]},{"cell_type":"code","source":["Features_Set2 = X[top_features[\"Features\"]]\n","\n","print(\"\\n\\nAutomatic Selected Features Set 2:\")\n","print(\"==================================\\n\")\n","Features_Set2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":510},"id":"1ZUD5KBvpMst","executionInfo":{"status":"ok","timestamp":1645568888606,"user_tz":300,"elapsed":14,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"6f9d6398-ded7-4e44-a50e-23decaf4ebc8"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Automatic Selected Features Set 2:\n","==================================\n","\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-3203287d-4d00-4227-8a4c-1cbfeae9f0bf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean_idur</th>\n","      <th>tot_time</th>\n","      <th>median_idur</th>\n","      <th>idur.146</th>\n","      <th>idur.142</th>\n","      <th>idur.93</th>\n","      <th>max_idur</th>\n","      <th>iraw.157</th>\n","      <th>idur.84</th>\n","      <th>idur.48</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.254294</td>\n","      <td>0.251140</td>\n","      <td>0.246154</td>\n","      <td>0.125261</td>\n","      <td>0.200000</td>\n","      <td>0.087379</td>\n","      <td>0.037668</td>\n","      <td>0.0</td>\n","      <td>0.063361</td>\n","      <td>0.088608</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.379208</td>\n","      <td>0.373250</td>\n","      <td>0.379487</td>\n","      <td>0.060543</td>\n","      <td>0.126984</td>\n","      <td>0.031553</td>\n","      <td>0.090583</td>\n","      <td>0.0</td>\n","      <td>0.071625</td>\n","      <td>0.071730</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.382986</td>\n","      <td>0.375825</td>\n","      <td>0.405128</td>\n","      <td>0.198330</td>\n","      <td>0.187302</td>\n","      <td>0.050971</td>\n","      <td>0.069955</td>\n","      <td>1.0</td>\n","      <td>0.179063</td>\n","      <td>0.236287</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.318125</td>\n","      <td>0.318526</td>\n","      <td>0.369231</td>\n","      <td>0.156576</td>\n","      <td>0.082540</td>\n","      <td>0.058252</td>\n","      <td>0.047534</td>\n","      <td>1.0</td>\n","      <td>0.085399</td>\n","      <td>0.210970</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.451111</td>\n","      <td>0.440850</td>\n","      <td>0.441026</td>\n","      <td>0.185804</td>\n","      <td>0.088889</td>\n","      <td>0.024272</td>\n","      <td>0.078924</td>\n","      <td>1.0</td>\n","      <td>0.107438</td>\n","      <td>0.092827</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1631</th>\n","      <td>0.179700</td>\n","      <td>0.177477</td>\n","      <td>0.174359</td>\n","      <td>0.075157</td>\n","      <td>0.066667</td>\n","      <td>0.033981</td>\n","      <td>0.045740</td>\n","      <td>1.0</td>\n","      <td>0.132231</td>\n","      <td>0.075949</td>\n","    </tr>\n","    <tr>\n","      <th>1632</th>\n","      <td>0.283604</td>\n","      <td>0.274478</td>\n","      <td>0.235897</td>\n","      <td>0.114823</td>\n","      <td>0.047619</td>\n","      <td>0.075243</td>\n","      <td>0.115695</td>\n","      <td>1.0</td>\n","      <td>0.046832</td>\n","      <td>0.223629</td>\n","    </tr>\n","    <tr>\n","      <th>1633</th>\n","      <td>0.386364</td>\n","      <td>0.375396</td>\n","      <td>0.215385</td>\n","      <td>0.221294</td>\n","      <td>0.123810</td>\n","      <td>0.067961</td>\n","      <td>0.198206</td>\n","      <td>1.0</td>\n","      <td>0.041322</td>\n","      <td>0.358650</td>\n","    </tr>\n","    <tr>\n","      <th>1634</th>\n","      <td>0.147756</td>\n","      <td>0.147916</td>\n","      <td>0.082051</td>\n","      <td>0.068894</td>\n","      <td>0.031746</td>\n","      <td>0.067961</td>\n","      <td>0.140807</td>\n","      <td>1.0</td>\n","      <td>0.035813</td>\n","      <td>0.278481</td>\n","    </tr>\n","    <tr>\n","      <th>1635</th>\n","      <td>0.207809</td>\n","      <td>0.207039</td>\n","      <td>0.194872</td>\n","      <td>0.056367</td>\n","      <td>0.060317</td>\n","      <td>0.041262</td>\n","      <td>0.089686</td>\n","      <td>1.0</td>\n","      <td>0.044077</td>\n","      <td>0.122363</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1636 rows × 10 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3203287d-4d00-4227-8a4c-1cbfeae9f0bf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3203287d-4d00-4227-8a4c-1cbfeae9f0bf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3203287d-4d00-4227-8a4c-1cbfeae9f0bf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      mean_idur  tot_time  median_idur  ...  iraw.157   idur.84   idur.48\n","0      0.254294  0.251140     0.246154  ...       0.0  0.063361  0.088608\n","1      0.379208  0.373250     0.379487  ...       0.0  0.071625  0.071730\n","2      0.382986  0.375825     0.405128  ...       1.0  0.179063  0.236287\n","3      0.318125  0.318526     0.369231  ...       1.0  0.085399  0.210970\n","4      0.451111  0.440850     0.441026  ...       1.0  0.107438  0.092827\n","...         ...       ...          ...  ...       ...       ...       ...\n","1631   0.179700  0.177477     0.174359  ...       1.0  0.132231  0.075949\n","1632   0.283604  0.274478     0.235897  ...       1.0  0.046832  0.223629\n","1633   0.386364  0.375396     0.215385  ...       1.0  0.041322  0.358650\n","1634   0.147756  0.147916     0.082051  ...       1.0  0.035813  0.278481\n","1635   0.207809  0.207039     0.194872  ...       1.0  0.044077  0.122363\n","\n","[1636 rows x 10 columns]"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"qhyid03rsNsc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645569039454,"user_tz":300,"elapsed":150858,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}},"outputId":"2eb4038d-0960-4a7a-8f3f-0b94aee42319"},"source":["\n","i = 0\n","for train_ix, test_ix in k_fold.split(Features_Set2):\n","    i = i + 1\n","    sheet = wb.add_sheet('fold'+str(i), cell_overwrite_ok=True) \n","\n","    sheet.write(0, 0, 'Model')\n","    sheet.write(0, 1, 'dataset')\n","    sheet.write(0, 2, 'threshold')\n","    sheet.write(0, 3, 'Precision')\n","    sheet.write(0, 4, 'Recall')\n","    sheet.write(0, 5, 'F1 Score')\n","    sheet.write(0, 6, 'weighted Kappa')\n","    sheet.write(0, 7, 'ROC AUC')\n","    sheet.write(0, 8, 'FPR')\n","    sheet.write(0, 9, 'tp')\n","    sheet.write(0, 10, 'fn')\n","    sheet.write(0, 11, 'fp')\n","    sheet.write(0, 12, 'tn')\n","    sheet.write(0, 13, 'total test samples')\n","    sheet.write(0, 14, 'rate of predicted cheaters')\n","    sheet.write(0, 15, 'real cheaters in testset')\n","    sheet.write(0, 16, 'total train samples')\n","\n","    # kfold\n","    # train_x, train_y, test_x, test_y = Features_Set2[train_ix], Y[train_ix], Features_Set2[test_ix], Y[test_ix]\n","    train_x, train_y, test_x, test_y = Features_Set2.iloc[train_ix], Y[train_ix], Features_Set2.iloc[test_ix], Y[test_ix]\n","\n","\n","    ###### SMOTE and RandomUnderSampler (for balancing data) ############\n","\n","    # both 33%\n","    # over = SMOTE(sampling_strategy=0.4)\n","    # under = RandomUnderSampler(sampling_strategy=0.5)\n","    # steps = [('o', over), ('u', under)]\n","\n","    # both 50%\n","    over = SMOTE(sampling_strategy=0.4, random_state=20)\n","    under = RandomUnderSampler(sampling_strategy=1, random_state=20)\n","    steps = [('o', over), ('u', under)]\n","\n","    # only smote 50%\n","    # over = SMOTE(sampling_strategy=1)\n","    # steps = [('o', over)]\n","\n","    # # only smote 33%\n","    # over = SMOTE(sampling_strategy=0.5)\n","    # steps = [('o', over)]\n","\n","    # # only undersampling 50%\n","    # under = RandomUnderSampler(sampling_strategy=1)\n","    # steps = [('u', under)]\n","\n","    # # only undersampling 33%\n","    # under = RandomUnderSampler(sampling_strategy=0.5)\n","    # steps = [('u', under)]\n","    \n","    # both 50% with high over\n","    # over = SMOTE(sampling_strategy=0.8)\n","    # under = RandomUnderSampler(sampling_strategy=1)\n","    # steps = [('o', over), ('u', under)]\n","\n","    pipeline = Pipeline(steps=steps)\n","\n","    x_smote, y_smote = pipeline.fit_resample(train_x, train_y)\n","\n","    # x1_smote, y1_smote = pipeline1.fit_resample(train_x1, train_y)\n","    # x2_smote, y2_smote = pipeline2.fit_resample(train_x2, train_y)\n","\n","    #### no resampling ###\n","    # x_smote, y_smote = train_x, train_y\n","\n","    size_trainset = len(y_smote)\n","\n"," ###### eight models #################\n","    ###\n","#     model1 = DecisionTreeClassifier(criterion=\"entropy\", max_features=\"auto\", splitter=\"best\")\n","#     # Fit, Predict\n","#     model1.fit(x_smote, y_smote)\n","#     probs1 = model1.predict_proba(test_x)\n","#     probs1 = probs1[:, 1]\n","\n","#     pred1 = (probs1 >= 0.7).astype(bool) # set threshold as 0.7\n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred1).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs1)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(1, 0, \"Decision Tree\")\n","#     sheet.write(1, 1, \"iraw_idur_OEF\")\n","#     sheet.write(1, 2, \"0.7\")\n","#     sheet.write(1, 3, precision_score(test_y, pred1))\n","#     sheet.write(1, 4, recall_score(test_y, pred1))\n","#     sheet.write(1, 5, f1_score(test_y, pred1))\n","#     sheet.write(1, 6, cohen_kappa_score(test_y, pred1, weights = 'quadratic'))\n","#     sheet.write(1, 7, auc)\n","#     sheet.write(1, 8, fpr)\n","\n","#     sheet.write(1, 9, str(tp))\n","#     sheet.write(1, 10, str(fn))\n","#     sheet.write(1, 11, str(fp))\n","#     sheet.write(1, 12, str(tn))\n","#     sheet.write(1, 13, str(tot_n))\n","#     sheet.write(1, 14, str(fptp_rate))\n","#     sheet.write(1, 15, str(real_cheaters))\n","#     sheet.write(1, 16, str(size_trainset))\n","\n","#     precision1_1 = np.append(precision1_1, precision_score(test_y, pred1))\n","#     recall1_1 = np.append(recall1_1, recall_score(test_y, pred1))\n","#     f1_score1_1 = np.append(f1_score1_1, f1_score(test_y, pred1))\n","#     kappa1_1 = np.append(kappa1_1, cohen_kappa_score(test_y, pred1, weights = 'quadratic'))\n","#     roc1_1 = np.append(roc1_1, auc)\n","#     fpr1_1 = np.append(fpr1_1, fpr)\n","\n","\n","#     ###########\n","#     pred1 = (probs1 >= 0.5).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred1).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs1)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(2, 0, \"Decision Tree\")\n","#     sheet.write(2, 1, \"iraw_idur_OEF\")\n","#     sheet.write(2, 2, \"0.5\")\n","#     sheet.write(2, 3, precision_score(test_y, pred1))\n","#     sheet.write(2, 4, recall_score(test_y, pred1))\n","#     sheet.write(2, 5, f1_score(test_y, pred1))\n","#     sheet.write(2, 6, cohen_kappa_score(test_y, pred1, weights = 'quadratic'))\n","#     sheet.write(2, 7, auc)\n","#     sheet.write(2, 8, fpr)\n","\n","#     sheet.write(2, 9, str(tp))\n","#     sheet.write(2, 10, str(fn))\n","#     sheet.write(2, 11, str(fp))\n","#     sheet.write(2, 12, str(tn))\n","#     sheet.write(2, 13, str(tot_n))\n","#     sheet.write(2, 14, str(fptp_rate))\n","#     sheet.write(2, 15, str(real_cheaters))\n","#     sheet.write(2, 16, str(size_trainset))\n","\n","#     precision1_2 = np.append(precision1_2, precision_score(test_y, pred1))\n","#     recall1_2 = np.append(recall1_2, recall_score(test_y, pred1))\n","#     f1_score1_2 = np.append(f1_score1_2, f1_score(test_y, pred1))\n","#     kappa1_2 = np.append(kappa1_2, cohen_kappa_score(test_y, pred1, weights = 'quadratic'))\n","#     roc1_2 = np.append(roc1_2, auc)\n","#     fpr1_2 = np.append(fpr1_2, fpr)\n","\n","#     ###########\n","#     pred1 = (probs1 >= 0.97).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred1).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs1)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(3, 0, \"Decision Tree\")\n","#     sheet.write(3, 1, \"iraw_idur_OEF\")\n","#     sheet.write(3, 2, \"0.97\")\n","#     sheet.write(3, 3, precision_score(test_y, pred1))\n","#     sheet.write(3, 4, recall_score(test_y, pred1))\n","#     sheet.write(3, 5, f1_score(test_y, pred1))\n","#     sheet.write(3, 6, cohen_kappa_score(test_y, pred1, weights = 'quadratic'))\n","#     sheet.write(3, 7, auc)\n","#     sheet.write(3, 8, fpr)\n","\n","#     sheet.write(3, 9, str(tp))\n","#     sheet.write(3, 10, str(fn))\n","#     sheet.write(3, 11, str(fp))\n","#     sheet.write(3, 12, str(tn))\n","#     sheet.write(3, 13, str(tot_n))\n","#     sheet.write(3, 14, str(fptp_rate))\n","#     sheet.write(3, 15, str(real_cheaters))\n","#     sheet.write(3, 16, str(size_trainset))\n","\n","#     precision1_3 = np.append(precision1_3, precision_score(test_y, pred1))\n","#     recall1_3 = np.append(recall1_3, recall_score(test_y, pred1))\n","#     f1_score1_3 = np.append(f1_score1_3, f1_score(test_y, pred1))\n","#     kappa1_3 = np.append(kappa1_3, cohen_kappa_score(test_y, pred1, weights = 'quadratic'))\n","#     roc1_3 = np.append(roc1_3, auc)\n","#     fpr1_3 = np.append(fpr1_3, fpr)\n","\n","\n","\n","# ############################    ###\n","#     model2 = SVC(kernel='linear', probability=True)\n","#     # Fit, Predict\n","#     model2.fit(x_smote, y_smote)\n","#     probs2 = model2.predict_proba(test_x)\n","#     probs2 = probs2[:, 1]\n","\n","#     pred2 = (probs2 >= 0.7).astype(bool) # set threshold as 0.7\n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred2).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs2)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(4, 0, \"Support Vector Machine\")\n","#     sheet.write(4, 1, \"iraw_idur_OEF\")\n","#     sheet.write(4, 2, \"0.7\")\n","#     sheet.write(4, 3, precision_score(test_y, pred2))\n","#     sheet.write(4, 4, recall_score(test_y, pred2))\n","#     sheet.write(4, 5, f1_score(test_y, pred2))\n","#     sheet.write(4, 6, cohen_kappa_score(test_y, pred2, weights = 'quadratic'))\n","#     sheet.write(4, 7, auc)\n","#     sheet.write(4, 8, fpr)\n","\n","#     sheet.write(4, 9, str(tp))\n","#     sheet.write(4, 10, str(fn))\n","#     sheet.write(4, 11, str(fp))\n","#     sheet.write(4, 12, str(tn))\n","#     sheet.write(4, 13, str(tot_n))\n","#     sheet.write(4, 14, str(fptp_rate))\n","#     sheet.write(4, 15, str(real_cheaters))\n","#     sheet.write(4, 16, str(size_trainset))\n","\n","#     precision2_1 = np.append(precision2_1, precision_score(test_y, pred2))\n","#     recall2_1 = np.append(recall2_1, recall_score(test_y, pred2))\n","#     f1_score2_1 = np.append(f1_score2_1, f1_score(test_y, pred2))\n","#     kappa2_1 = np.append(kappa2_1, cohen_kappa_score(test_y, pred2, weights = 'quadratic'))\n","#     roc2_1 = np.append(roc2_1, auc)\n","#     fpr2_1 = np.append(fpr2_1, fpr)\n","\n","\n","#     ############\n","#     pred2 = (probs2 >= 0.5).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred2).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs2)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(5, 0, \"Support Vector Machine\")\n","#     sheet.write(5, 1, \"iraw_idur_OEF\")\n","#     sheet.write(5, 2, \"0.5\")\n","#     sheet.write(5, 3, precision_score(test_y, pred2))\n","#     sheet.write(5, 4, recall_score(test_y, pred2))\n","#     sheet.write(5, 5, f1_score(test_y, pred2))\n","#     sheet.write(5, 6, cohen_kappa_score(test_y, pred2, weights = 'quadratic'))\n","#     sheet.write(5, 7, auc)\n","#     sheet.write(5, 8, fpr)\n","#     sheet.write(5, 9, str(tp))\n","#     sheet.write(5, 10, str(fn))\n","#     sheet.write(5, 11, str(fp))\n","#     sheet.write(5, 12, str(tn))\n","#     sheet.write(5, 13, str(tot_n))\n","#     sheet.write(5, 14, str(fptp_rate))\n","#     sheet.write(5, 15, str(real_cheaters))\n","#     sheet.write(5, 16, str(size_trainset))\n","\n","#     precision2_2 = np.append(precision2_2, precision_score(test_y, pred2))\n","#     recall2_2 = np.append(recall2_2, recall_score(test_y, pred2))\n","#     f1_score2_2 = np.append(f1_score2_2, f1_score(test_y, pred2))\n","#     kappa2_2 = np.append(kappa2_2, cohen_kappa_score(test_y, pred2, weights = 'quadratic'))\n","#     roc2_2 = np.append(roc2_2, auc)\n","#     fpr2_2 = np.append(fpr2_2, fpr)\n","\n","#    ############\n","#     pred2 = (probs2 >= 0.97).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred2).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs2)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(6, 0, \"Support Vector Machine\")\n","#     sheet.write(6, 1, \"iraw_idur_OEF\")\n","#     sheet.write(6, 2, \"0.97\")\n","#     sheet.write(6, 3, precision_score(test_y, pred2))\n","#     sheet.write(6, 4, recall_score(test_y, pred2))\n","#     sheet.write(6, 5, f1_score(test_y, pred2))\n","#     sheet.write(6, 6, cohen_kappa_score(test_y, pred2, weights = 'quadratic'))\n","#     sheet.write(6, 7, auc)\n","#     sheet.write(6, 8, fpr)\n","#     sheet.write(6, 9, str(tp))\n","#     sheet.write(6, 10, str(fn))\n","#     sheet.write(6, 11, str(fp))\n","#     sheet.write(6, 12, str(tn))\n","#     sheet.write(6, 13, str(tot_n))\n","#     sheet.write(6, 14, str(fptp_rate))\n","#     sheet.write(6, 15, str(real_cheaters))\n","#     sheet.write(6, 16, str(size_trainset))\n","\n","#     precision2_3 = np.append(precision2_3, precision_score(test_y, pred2))\n","#     recall2_3 = np.append(recall2_3, recall_score(test_y, pred2))\n","#     f1_score2_3 = np.append(f1_score2_3, f1_score(test_y, pred2))\n","#     kappa2_3 = np.append(kappa2_3, cohen_kappa_score(test_y, pred2, weights = 'quadratic'))\n","#     roc2_3 = np.append(roc2_3, auc)\n","#     fpr2_3 = np.append(fpr2_3, fpr)\n","\n","\n","\n","# ###################################\n","#     ###\n","#     model3 = LogisticRegression(C=2, multi_class=\"multinomial\", solver=\"newton-cg\")\n","#     # Fit, Predict\n","#     model3.fit(x_smote, y_smote)\n","#     probs3 = model3.predict_proba(test_x)\n","#     probs3 = probs3[:, 1]\n","\n","#     pred3 = (probs3 >= 0.7).astype(bool) # set threshold as 0.7\n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred3).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs3)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(7, 0, \"Logistic Regression\")\n","#     sheet.write(7, 1, \"iraw_idur_OEF\")\n","#     sheet.write(7, 2, \"0.7\")\n","#     sheet.write(7, 3, precision_score(test_y, pred3))\n","#     sheet.write(7, 4, recall_score(test_y, pred3))\n","#     sheet.write(7, 5, f1_score(test_y, pred3))\n","#     sheet.write(7, 6, cohen_kappa_score(test_y, pred3, weights = 'quadratic'))\n","#     sheet.write(7, 7, auc)\n","#     sheet.write(7, 8, fpr)\n","#     sheet.write(7, 9, str(tp))\n","#     sheet.write(7, 10, str(fn))\n","#     sheet.write(7, 11, str(fp))\n","#     sheet.write(7, 12, str(tn))\n","#     sheet.write(7, 13, str(tot_n))\n","#     sheet.write(7, 14, str(fptp_rate))\n","#     sheet.write(7, 15, str(real_cheaters))\n","#     sheet.write(7, 16, str(size_trainset))\n","\n","#     precision3_1 = np.append(precision3_1, precision_score(test_y, pred3))\n","#     recall3_1 = np.append(recall3_1, recall_score(test_y, pred3))\n","#     f1_score3_1 = np.append(f1_score3_1, f1_score(test_y, pred3))\n","#     kappa3_1 = np.append(kappa3_1, cohen_kappa_score(test_y, pred3, weights = 'quadratic'))\n","#     roc3_1 = np.append(roc3_1, auc)\n","#     fpr3_1 = np.append(fpr3_1, fpr)\n","\n","#     ######\n","#     pred3 = (probs3 >= 0.5).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred3).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs3)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(8, 0, \"Logistic Regression\")\n","#     sheet.write(8, 1, \"iraw_idur_OEF\")\n","#     sheet.write(8, 2, \"0.5\")\n","#     sheet.write(8, 3, precision_score(test_y, pred3))\n","#     sheet.write(8, 4, recall_score(test_y, pred3))\n","#     sheet.write(8, 5, f1_score(test_y, pred3))\n","#     sheet.write(8, 6, cohen_kappa_score(test_y, pred3, weights = 'quadratic'))\n","#     sheet.write(8, 7, auc)\n","#     sheet.write(8, 8, fpr)\n","#     sheet.write(8, 9, str(tp))\n","#     sheet.write(8, 10, str(fn))\n","#     sheet.write(8, 11, str(fp))\n","#     sheet.write(8, 12, str(tn))\n","#     sheet.write(8, 13, str(tot_n))\n","#     sheet.write(8, 14, str(fptp_rate))\n","#     sheet.write(8, 15, str(real_cheaters))\n","#     sheet.write(8, 16, str(size_trainset))\n","\n","#     precision3_2 = np.append(precision3_2, precision_score(test_y, pred3))\n","#     recall3_2 = np.append(recall3_2, recall_score(test_y, pred3))\n","#     f1_score3_2 = np.append(f1_score3_2, f1_score(test_y, pred3))\n","#     kappa3_2 = np.append(kappa3_2, cohen_kappa_score(test_y, pred3, weights = 'quadratic'))\n","#     roc3_2 = np.append(roc3_2, auc)\n","#     fpr3_2 = np.append(fpr3_2, fpr)\n","\n","#     ######\n","#     pred3 = (probs3 >= 0.97).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred3).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs3)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(9, 0, \"Logistic Regression\")\n","#     sheet.write(9, 1, \"iraw_idur_OEF\")\n","#     sheet.write(9, 2, \"0.97\")\n","#     sheet.write(9, 3, precision_score(test_y, pred3))\n","#     sheet.write(9, 4, recall_score(test_y, pred3))\n","#     sheet.write(9, 5, f1_score(test_y, pred3))\n","#     sheet.write(9, 6, cohen_kappa_score(test_y, pred3, weights = 'quadratic'))\n","#     sheet.write(9, 7, auc)\n","#     sheet.write(9, 8, fpr)\n","#     sheet.write(9, 9, str(tp))\n","#     sheet.write(9, 10, str(fn))\n","#     sheet.write(9, 11, str(fp))\n","#     sheet.write(9, 12, str(tn))\n","#     sheet.write(9, 13, str(tot_n))\n","#     sheet.write(9, 14, str(fptp_rate))\n","#     sheet.write(9, 15, str(real_cheaters))\n","#     sheet.write(9, 16, str(size_trainset))\n","\n","#     precision3_3 = np.append(precision3_3, precision_score(test_y, pred3))\n","#     recall3_3 = np.append(recall3_3, recall_score(test_y, pred3))\n","#     f1_score3_3 = np.append(f1_score3_3, f1_score(test_y, pred3))\n","#     kappa3_3 = np.append(kappa3_3, cohen_kappa_score(test_y, pred3, weights = 'quadratic'))\n","#     roc3_3 = np.append(roc3_3, auc)\n","#     fpr3_3 = np.append(fpr3_3, fpr)\n","\n"," \n","\n","# #########################################\n","#     ###\n","#     model4 = LinearDiscriminantAnalysis(shrinkage=\"auto\", solver=\"eigen\")\n","#     # Fit, Predict\n","#     model4.fit(x_smote, y_smote)\n","#     probs4 = model4.predict_proba(test_x)\n","#     probs4 = probs4[:, 1]\n","\n","#     pred4 = (probs4 >= 0.7).astype(bool) # set threshold as 0.7\n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred4).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs4)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(10, 0, \"Discriminant Analysis\")\n","#     sheet.write(10, 1, \"iraw_idur_OEF\")\n","#     sheet.write(10, 2, \"0.7\")\n","#     sheet.write(10, 3, precision_score(test_y, pred4))\n","#     sheet.write(10, 4, recall_score(test_y, pred4))\n","#     sheet.write(10, 5, f1_score(test_y, pred4))\n","#     sheet.write(10, 6, cohen_kappa_score(test_y, pred4, weights = 'quadratic'))\n","#     sheet.write(10, 7, auc)\n","#     sheet.write(10, 8, fpr)\n","#     sheet.write(10, 9, str(tp))\n","#     sheet.write(10, 10, str(fn))\n","#     sheet.write(10, 11, str(fp))\n","#     sheet.write(10, 12, str(tn))\n","#     sheet.write(10, 13, str(tot_n))\n","#     sheet.write(10, 14, str(fptp_rate))\n","#     sheet.write(10, 15, str(real_cheaters))\n","#     sheet.write(10, 16, str(size_trainset))\n","\n","#     precision4_1 = np.append(precision4_1, precision_score(test_y, pred4))\n","#     recall4_1 = np.append(recall4_1, recall_score(test_y, pred4))\n","#     f1_score4_1 = np.append(f1_score4_1, f1_score(test_y, pred4))\n","#     kappa4_1 = np.append(kappa4_1, cohen_kappa_score(test_y, pred4, weights = 'quadratic'))\n","#     roc4_1 = np.append(roc4_1, auc)\n","#     fpr4_1 = np.append(fpr4_1, fpr)\n","\n","#     ############\n","#     pred4 = (probs4 >= 0.5).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred4).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs4)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(11, 0, \"Discriminant Analysis\")\n","#     sheet.write(11, 1, \"iraw_idur_OEF\")\n","#     sheet.write(11, 2, \"0.5\")\n","#     sheet.write(11, 3, precision_score(test_y, pred4))\n","#     sheet.write(11, 4, recall_score(test_y, pred4))\n","#     sheet.write(11, 5, f1_score(test_y, pred4))\n","#     sheet.write(11, 6, cohen_kappa_score(test_y, pred4, weights = 'quadratic'))\n","#     sheet.write(11, 7, auc)\n","#     sheet.write(11, 8, fpr)\n","#     sheet.write(11, 9, str(tp))\n","#     sheet.write(11, 10, str(fn))\n","#     sheet.write(11, 11, str(fp))\n","#     sheet.write(11, 12, str(tn))\n","#     sheet.write(11, 13, str(tot_n))\n","#     sheet.write(11, 14, str(fptp_rate))\n","#     sheet.write(11, 15, str(real_cheaters))\n","#     sheet.write(11, 16, str(size_trainset))\n","\n","#     precision4_2 = np.append(precision4_2, precision_score(test_y, pred4))\n","#     recall4_2 = np.append(recall4_2, recall_score(test_y, pred4))\n","#     f1_score4_2 = np.append(f1_score4_2, f1_score(test_y, pred4))\n","#     kappa4_2 = np.append(kappa4_2, cohen_kappa_score(test_y, pred4, weights = 'quadratic'))\n","#     roc4_2 = np.append(roc4_2, auc)\n","#     fpr4_2 = np.append(fpr4_2, fpr)\n","\n","#     ############\n","#     pred4 = (probs4 >= 0.97).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred4).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs4)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(12, 0, \"Discriminant Analysis\")\n","#     sheet.write(12, 1, \"iraw_idur_OEF\")\n","#     sheet.write(12, 2, \"0.97\")\n","#     sheet.write(12, 3, precision_score(test_y, pred4))\n","#     sheet.write(12, 4, recall_score(test_y, pred4))\n","#     sheet.write(12, 5, f1_score(test_y, pred4))\n","#     sheet.write(12, 6, cohen_kappa_score(test_y, pred4, weights = 'quadratic'))\n","#     sheet.write(12, 7, auc)\n","#     sheet.write(12, 8, fpr)\n","#     sheet.write(12, 9, str(tp))\n","#     sheet.write(12, 10, str(fn))\n","#     sheet.write(12, 11, str(fp))\n","#     sheet.write(12, 12, str(tn))\n","#     sheet.write(12, 13, str(tot_n))\n","#     sheet.write(12, 14, str(fptp_rate))\n","#     sheet.write(12, 15, str(real_cheaters))\n","#     sheet.write(12, 16, str(size_trainset))\n","\n","#     precision4_3 = np.append(precision4_3, precision_score(test_y, pred4))\n","#     recall4_3 = np.append(recall4_3, recall_score(test_y, pred4))\n","#     f1_score4_3 = np.append(f1_score4_3, f1_score(test_y, pred4))\n","#     kappa4_3 = np.append(kappa4_3, cohen_kappa_score(test_y, pred4, weights = 'quadratic'))\n","#     roc4_3 = np.append(roc4_3, auc)\n","#     fpr4_3 = np.append(fpr4_3, fpr)\n","\n"," \n"," ###############################################\n","#     ###\n","#     model5 = GaussianNB(var_smoothing=6.579332246575682e-08)\n","#     # Fit, Predict\n","#     model5.fit(x_smote, y_smote)\n","#     probs5 = model5.predict_proba(test_x)\n","#     probs5 = probs5[:, 1]\n","\n","#     pred5 = (probs5 >= 0.7).astype(bool) # set threshold as 0.7\n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred5).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs5)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(13, 0, \"Naive Bayes\")\n","#     sheet.write(13, 1, \"iraw_idur_OEF\")\n","#     sheet.write(13, 2, \"0.7\")\n","#     sheet.write(13, 3, precision_score(test_y, pred5))\n","#     sheet.write(13, 4, recall_score(test_y, pred5))\n","#     sheet.write(13, 5, f1_score(test_y, pred5))\n","#     sheet.write(13, 6, cohen_kappa_score(test_y, pred5, weights = 'quadratic'))\n","#     sheet.write(13, 7, auc)\n","#     sheet.write(13, 8, fpr)\n","#     sheet.write(13, 9, str(tp))\n","#     sheet.write(13, 10, str(fn))\n","#     sheet.write(13, 11, str(fp))\n","#     sheet.write(13, 12, str(tn))\n","#     sheet.write(13, 13, str(tot_n))\n","#     sheet.write(13, 14, str(fptp_rate))\n","#     sheet.write(13, 15, str(real_cheaters))\n","#     sheet.write(13, 16, str(size_trainset))\n","\n","#     precision5_1 = np.append(precision5_1, precision_score(test_y, pred5))\n","#     recall5_1 = np.append(recall5_1, recall_score(test_y, pred5))\n","#     f1_score5_1 = np.append(f1_score5_1, f1_score(test_y, pred5))\n","#     kappa5_1 = np.append(kappa5_1, cohen_kappa_score(test_y, pred5, weights = 'quadratic'))\n","#     roc5_1 = np.append(roc5_1, auc)\n","#     fpr5_1 = np.append(fpr5_1, fpr)\n","\n","\n","#     ###############\n","#     pred5 = (probs5 >= 0.5).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred5).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs5)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(14, 0, \"Naive Bayes\")\n","#     sheet.write(14, 1, \"iraw_idur_OEF\")\n","#     sheet.write(14, 2, \"0.5\")\n","#     sheet.write(14, 3, precision_score(test_y, pred5))\n","#     sheet.write(14, 4, recall_score(test_y, pred5))\n","#     sheet.write(14, 5, f1_score(test_y, pred5))\n","#     sheet.write(14, 6, cohen_kappa_score(test_y, pred5, weights = 'quadratic'))\n","#     sheet.write(14, 7, auc)\n","#     sheet.write(14, 8, fpr)\n","#     sheet.write(14, 9, str(tp))\n","#     sheet.write(14, 10, str(fn))\n","#     sheet.write(14, 11, str(fp))\n","#     sheet.write(14, 12, str(tn))\n","#     sheet.write(14, 13, str(tot_n))\n","#     sheet.write(14, 14, str(fptp_rate))\n","#     sheet.write(14, 15, str(real_cheaters))\n","#     sheet.write(14, 16, str(size_trainset))\n","\n","#     precision5_2 = np.append(precision5_2, precision_score(test_y, pred5))\n","#     recall5_2 = np.append(recall5_2, recall_score(test_y, pred5))\n","#     f1_score5_2 = np.append(f1_score5_2, f1_score(test_y, pred5))\n","#     kappa5_2 = np.append(kappa5_2, cohen_kappa_score(test_y, pred5, weights = 'quadratic'))\n","#     roc5_2 = np.append(roc5_2, auc)\n","#     fpr5_2 = np.append(fpr5_2, fpr)\n","\n","#     ###############\n","#     pred5 = (probs5 >= 0.97).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred5).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs5)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(15, 0, \"Naive Bayes\")\n","#     sheet.write(15, 1, \"iraw_idur_OEF\")\n","#     sheet.write(15, 2, \"0.97\")\n","#     sheet.write(15, 3, precision_score(test_y, pred5))\n","#     sheet.write(15, 4, recall_score(test_y, pred5))\n","#     sheet.write(15, 5, f1_score(test_y, pred5))\n","#     sheet.write(15, 6, cohen_kappa_score(test_y, pred5, weights = 'quadratic'))\n","#     sheet.write(15, 7, auc)\n","#     sheet.write(15, 8, fpr)\n","#     sheet.write(15, 9, str(tp))\n","#     sheet.write(15, 10, str(fn))\n","#     sheet.write(15, 11, str(fp))\n","#     sheet.write(15, 12, str(tn))\n","#     sheet.write(15, 13, str(tot_n))\n","#     sheet.write(15, 14, str(fptp_rate))\n","#     sheet.write(15, 15, str(real_cheaters))\n","#     sheet.write(15, 16, str(size_trainset))\n","\n","#     precision5_3 = np.append(precision5_3, precision_score(test_y, pred5))\n","#     recall5_3 = np.append(recall5_3, recall_score(test_y, pred5))\n","#     f1_score5_3 = np.append(f1_score5_3, f1_score(test_y, pred5))\n","#     kappa5_3 = np.append(kappa5_3, cohen_kappa_score(test_y, pred5, weights = 'quadratic'))\n","#     roc5_3 = np.append(roc5_3, auc)\n","#     fpr5_3 = np.append(fpr5_3, fpr)\n","\n"," \n","# ##############################################################\n","#     ###\n","#     model6 = MLPClassifier(activation=\"relu\", learning_rate=\"invscaling\", solver=\"adam\")\n","#     # Fit, Predict\n","#     model6.fit(x_smote, y_smote)\n","#     probs6 = model6.predict_proba(test_x)\n","#     probs6 = probs6[:, 1]\n","\n","#     pred6 = (probs6 >= 0.7).astype(bool) # set threshold as 0.7\n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred6).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs6)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(16, 0, \"Neural Network\")\n","#     sheet.write(16, 1, \"iraw_idur_OEF\")\n","#     sheet.write(16, 2, \"0.7\")\n","#     sheet.write(16, 3, precision_score(test_y, pred6))\n","#     sheet.write(16, 4, recall_score(test_y, pred6))\n","#     sheet.write(16, 5, f1_score(test_y, pred6))\n","#     sheet.write(16, 6, cohen_kappa_score(test_y, pred6, weights = 'quadratic'))\n","#     sheet.write(16, 7, auc)\n","#     sheet.write(16, 8, fpr)\n","#     sheet.write(16, 9, str(tp))\n","#     sheet.write(16, 10, str(fn))\n","#     sheet.write(16, 11, str(fp))\n","#     sheet.write(16, 12, str(tn))\n","#     sheet.write(16, 13, str(tot_n))\n","#     sheet.write(16, 14, str(fptp_rate))\n","#     sheet.write(16, 15, str(real_cheaters))\n","#     sheet.write(16, 16, str(size_trainset))\n","\n","#     precision6_1 = np.append(precision6_1, precision_score(test_y, pred6))\n","#     recall6_1 = np.append(recall6_1, recall_score(test_y, pred6))\n","#     f1_score6_1 = np.append(f1_score6_1, f1_score(test_y, pred6))\n","#     kappa6_1 = np.append(kappa6_1, cohen_kappa_score(test_y, pred6, weights = 'quadratic'))\n","#     roc6_1 = np.append(roc6_1, auc)\n","#     fpr6_1 = np.append(fpr6_1, fpr)\n","\n","#     ##################\n","#     pred6 = (probs6 >= 0.5).astype(bool)\n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred6).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs6)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(17, 0, \"Neural Network\")\n","#     sheet.write(17, 1, \"iraw_idur_OEF\")\n","#     sheet.write(17, 2, \"0.5\")\n","#     sheet.write(17, 3, precision_score(test_y, pred6))\n","#     sheet.write(17, 4, recall_score(test_y, pred6))\n","#     sheet.write(17, 5, f1_score(test_y, pred6))\n","#     sheet.write(17, 6, cohen_kappa_score(test_y, pred6, weights = 'quadratic'))\n","#     sheet.write(17, 7, auc)\n","#     sheet.write(17, 8, fpr)\n","#     sheet.write(17, 9, str(tp))\n","#     sheet.write(17, 10, str(fn))\n","#     sheet.write(17, 11, str(fp))\n","#     sheet.write(17, 12, str(tn))\n","#     sheet.write(17, 13, str(tot_n))\n","#     sheet.write(17, 14, str(fptp_rate))\n","#     sheet.write(17, 15, str(real_cheaters))\n","#     sheet.write(17, 16, str(size_trainset))\n","\n","#     precision6_2 = np.append(precision6_2, precision_score(test_y, pred6))\n","#     recall6_2 = np.append(recall6_2, recall_score(test_y, pred6))\n","#     f1_score6_2 = np.append(f1_score6_2, f1_score(test_y, pred6))\n","#     kappa6_2 = np.append(kappa6_2, cohen_kappa_score(test_y, pred6, weights = 'quadratic'))\n","#     roc6_2 = np.append(roc6_2, auc)\n","#     fpr6_2 = np.append(fpr6_2, fpr)\n","\n","#     ##################\n","#     pred6 = (probs6 >= 0.97).astype(bool)\n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred6).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs6)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(18, 0, \"Neural Network\")\n","#     sheet.write(18, 1, \"iraw_idur_OEF\")\n","#     sheet.write(18, 2, \"0.97\")\n","#     sheet.write(18, 3, precision_score(test_y, pred6))\n","#     sheet.write(18, 4, recall_score(test_y, pred6))\n","#     sheet.write(18, 5, f1_score(test_y, pred6))\n","#     sheet.write(18, 6, cohen_kappa_score(test_y, pred6, weights = 'quadratic'))\n","#     sheet.write(18, 7, auc)\n","#     sheet.write(18, 8, fpr)\n","#     sheet.write(18, 9, str(tp))\n","#     sheet.write(18, 10, str(fn))\n","#     sheet.write(18, 11, str(fp))\n","#     sheet.write(18, 12, str(tn))\n","#     sheet.write(18, 13, str(tot_n))\n","#     sheet.write(18, 14, str(fptp_rate))\n","#     sheet.write(18, 15, str(real_cheaters))\n","#     sheet.write(18, 16, str(size_trainset))\n","\n","#     precision6_3 = np.append(precision6_3, precision_score(test_y, pred6))\n","#     recall6_3 = np.append(recall6_3, recall_score(test_y, pred6))\n","#     f1_score6_3 = np.append(f1_score6_3, f1_score(test_y, pred6))\n","#     kappa6_3 = np.append(kappa6_3, cohen_kappa_score(test_y, pred6, weights = 'quadratic'))\n","#     roc6_3 = np.append(roc6_3, auc)\n","#     fpr6_3 = np.append(fpr6_3, fpr)\n","\n"," \n","# ############################################\n","#     ###\n","#     model7 = RandomForestClassifier(criterion=\"gini\", max_depth=500, max_features=\"auto\", min_samples_leaf=1, min_samples_split=2, n_estimators=911)\n","#     # Fit, Predict\n","#     model7.fit(x_smote, y_smote)\n","#     probs7 = model7.predict_proba(test_x)\n","#     probs7 = probs7[:, 1]\n","\n","#     pred7 = (probs7 >= 0.7).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred7).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs7)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(19, 0, \"Random Forest\")\n","#     sheet.write(19, 1, \"idur_OEF\")\n","#     sheet.write(19, 2, \"0.7\")\n","#     sheet.write(19, 3, precision_score(test_y, pred7))\n","#     sheet.write(19, 4, recall_score(test_y, pred7))\n","#     sheet.write(19, 5, f1_score(test_y, pred7))\n","#     sheet.write(19, 6, cohen_kappa_score(test_y, pred7, weights = 'quadratic'))\n","#     sheet.write(19, 7, auc)\n","#     sheet.write(19, 8, fpr)\n","#     sheet.write(19, 9, str(tp))\n","#     sheet.write(19, 10, str(fn))\n","#     sheet.write(19, 11, str(fp))\n","#     sheet.write(19, 12, str(tn))\n","#     sheet.write(19, 13, str(tot_n))\n","#     sheet.write(19, 14, str(fptp_rate))\n","#     sheet.write(19, 15, str(real_cheaters))\n","#     sheet.write(19, 16, str(size_trainset))\n","\n","#     precision7_1 = np.append(precision7_1, precision_score(test_y, pred7))\n","#     recall7_1 = np.append(recall7_1, recall_score(test_y, pred7))\n","#     f1_score7_1 = np.append(f1_score7_1, f1_score(test_y, pred7))\n","#     kappa7_1 = np.append(kappa7_1, cohen_kappa_score(test_y, pred7, weights = 'quadratic'))\n","#     roc7_1 = np.append(roc7_1, auc)\n","#     fpr7_1 = np.append(fpr7_1, fpr)\n","\n","#     ##################\n","#     pred7 = (probs7 >= 0.5).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred7).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs7)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(20, 0, \"Random Forest\")\n","#     sheet.write(20, 1, \"idur_OEF\")\n","#     sheet.write(20, 2, \"0.5\")\n","#     sheet.write(20, 3, precision_score(test_y, pred7))\n","#     sheet.write(20, 4, recall_score(test_y, pred7))\n","#     sheet.write(20, 5, f1_score(test_y, pred7))\n","#     sheet.write(20, 6, cohen_kappa_score(test_y, pred7, weights = 'quadratic'))\n","#     sheet.write(20, 7, auc)\n","#     sheet.write(20, 8, fpr)\n","#     sheet.write(20, 9, str(tp))\n","#     sheet.write(20, 10, str(fn))\n","#     sheet.write(20, 11, str(fp))\n","#     sheet.write(20, 12, str(tn))\n","#     sheet.write(20, 13, str(tot_n))\n","#     sheet.write(20, 14, str(fptp_rate))\n","#     sheet.write(20, 15, str(real_cheaters))\n","#     sheet.write(20, 16, str(size_trainset))\n","\n","#     precision7_2 = np.append(precision7_2, precision_score(test_y, pred7))\n","#     recall7_2 = np.append(recall7_2, recall_score(test_y, pred7))\n","#     f1_score7_2 = np.append(f1_score7_2, f1_score(test_y, pred7))\n","#     kappa7_2 = np.append(kappa7_2, cohen_kappa_score(test_y, pred7, weights = 'quadratic'))\n","#     roc7_2 = np.append(roc7_2, auc)\n","#     fpr7_2 = np.append(fpr7_2, fpr)\n","\n","#     ##################\n","#     pred7 = (probs7 >= 0.97).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred7).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs7)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(21, 0, \"Random Forest\")\n","#     sheet.write(21, 1, \"idur_OEF\")\n","#     sheet.write(21, 2, \"0.97\")\n","#     sheet.write(21, 3, precision_score(test_y, pred7))\n","#     sheet.write(21, 4, recall_score(test_y, pred7))\n","#     sheet.write(21, 5, f1_score(test_y, pred7))\n","#     sheet.write(21, 6, cohen_kappa_score(test_y, pred7, weights = 'quadratic'))\n","#     sheet.write(21, 7, auc)\n","#     sheet.write(21, 8, fpr)\n","#     sheet.write(21, 9, str(tp))\n","#     sheet.write(21, 10, str(fn))\n","#     sheet.write(21, 11, str(fp))\n","#     sheet.write(21, 12, str(tn))\n","#     sheet.write(21, 13, str(tot_n))\n","#     sheet.write(21, 14, str(fptp_rate))\n","#     sheet.write(21, 15, str(real_cheaters))\n","#     sheet.write(21, 16, str(size_trainset))\n","\n","#     precision7_3 = np.append(precision7_3, precision_score(test_y, pred7))\n","#     recall7_3 = np.append(recall7_3, recall_score(test_y, pred7))\n","#     f1_score7_3 = np.append(f1_score7_3, f1_score(test_y, pred7))\n","#     kappa7_3 = np.append(kappa7_3, cohen_kappa_score(test_y, pred7, weights = 'quadratic'))\n","#     roc7_3 = np.append(roc7_3, auc)\n","#     fpr7_3 = np.append(fpr7_3, fpr)\n","\n"," \n","# #################################################\n","#     ###\n","#     model8 = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100)\n","#     # Fit, Predict\n","#     model8.fit(x_smote, y_smote)\n","#     probs8 = model8.predict_proba(test_x)\n","#     probs8 = probs8[:, 1]\n","\n","#     pred8 = (probs8 >= 0.7).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred8).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs8)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(22, 0, \"Gradient Boosting\")\n","#     sheet.write(22, 1, \"iraw_OEF\")\n","#     sheet.write(22, 2, \"0.7\")\n","#     sheet.write(22, 3, precision_score(test_y, pred8))\n","#     sheet.write(22, 4, recall_score(test_y, pred8))\n","#     sheet.write(22, 5, f1_score(test_y, pred8))\n","#     sheet.write(22, 6, cohen_kappa_score(test_y, pred8, weights = 'quadratic'))\n","#     sheet.write(22, 7, auc)\n","#     sheet.write(22, 8, fpr)\n","#     sheet.write(22, 9, str(tp))\n","#     sheet.write(22, 10, str(fn))\n","#     sheet.write(22, 11, str(fp))\n","#     sheet.write(22, 12, str(tn))\n","#     sheet.write(22, 13, str(tot_n))\n","#     sheet.write(22, 14, str(fptp_rate))\n","#     sheet.write(22, 15, str(real_cheaters))\n","#     sheet.write(22, 16, str(size_trainset))\n","\n","#     precision8_1 = np.append(precision8_1, precision_score(test_y, pred8))\n","#     recall8_1 = np.append(recall8_1, recall_score(test_y, pred8))\n","#     f1_score8_1 = np.append(f1_score8_1, f1_score(test_y, pred8))\n","#     kappa8_1 = np.append(kappa8_1, cohen_kappa_score(test_y, pred8, weights = 'quadratic'))\n","#     roc8_1 = np.append(roc8_1, auc)\n","#     fpr8_1 = np.append(fpr8_1, fpr)\n","\n","#     ######################\n","#     pred8 = (probs8 >= 0.5).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred8).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs8)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(23, 0, \"Gradient Boosting\")\n","#     sheet.write(23, 1, \"iraw_OEF\")\n","#     sheet.write(23, 2, \"0.5\")\n","#     sheet.write(23, 3, precision_score(test_y, pred8))\n","#     sheet.write(23, 4, recall_score(test_y, pred8))\n","#     sheet.write(23, 5, f1_score(test_y, pred8))\n","#     sheet.write(23, 6, cohen_kappa_score(test_y, pred8, weights = 'quadratic'))\n","#     sheet.write(23, 7, auc)\n","#     sheet.write(23, 8, fpr)\n","#     sheet.write(23, 9, str(tp))\n","#     sheet.write(23, 10, str(fn))\n","#     sheet.write(23, 11, str(fp))\n","#     sheet.write(23, 12, str(tn))\n","#     sheet.write(23, 13, str(tot_n))\n","#     sheet.write(23, 14, str(fptp_rate))\n","#     sheet.write(23, 15, str(real_cheaters))\n","#     sheet.write(23, 16, str(size_trainset))\n","\n","#     precision8_2 = np.append(precision8_2, precision_score(test_y, pred8))\n","#     recall8_2 = np.append(recall8_2, recall_score(test_y, pred8))\n","#     f1_score8_2 = np.append(f1_score8_2, f1_score(test_y, pred8))\n","#     kappa8_2 = np.append(kappa8_2, cohen_kappa_score(test_y, pred8, weights = 'quadratic'))\n","#     roc8_2 = np.append(roc8_2, auc)\n","#     fpr8_2 = np.append(fpr8_2, fpr)\n","\n","#     ######################\n","#     pred8 = (probs8 >= 0.97).astype(bool) \n","\n","#     tn, fp, fn, tp = confusion_matrix(test_y, pred8).ravel()\n","#     fpr = (fp)/(fp+tn)\n","#     auc = roc_auc_score(test_y, probs8)\n","#     fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","#     tot_n =  tn+fp+fn+tp\n","#     real_cheaters = tp+fn\n","\n","#     #### write to excel sheet ####\n","#     sheet.write(24, 0, \"Gradient Boosting\")\n","#     sheet.write(24, 1, \"iraw_OEF\")\n","#     sheet.write(24, 2, \"0.97\")\n","#     sheet.write(24, 3, precision_score(test_y, pred8))\n","#     sheet.write(24, 4, recall_score(test_y, pred8))\n","#     sheet.write(24, 5, f1_score(test_y, pred8))\n","#     sheet.write(24, 6, cohen_kappa_score(test_y, pred8, weights = 'quadratic'))\n","#     sheet.write(24, 7, auc)\n","#     sheet.write(24, 8, fpr)\n","#     sheet.write(24, 9, str(tp))\n","#     sheet.write(24, 10, str(fn))\n","#     sheet.write(24, 11, str(fp))\n","#     sheet.write(24, 12, str(tn))\n","#     sheet.write(24, 13, str(tot_n))\n","#     sheet.write(24, 14, str(fptp_rate))\n","#     sheet.write(24, 15, str(real_cheaters))\n","#     sheet.write(24, 16, str(size_trainset))\n","\n","#     precision8_3 = np.append(precision8_3, precision_score(test_y, pred8))\n","#     recall8_3 = np.append(recall8_3, recall_score(test_y, pred8))\n","#     f1_score8_3 = np.append(f1_score8_3, f1_score(test_y, pred8))\n","#     kappa8_3 = np.append(kappa8_3, cohen_kappa_score(test_y, pred8, weights = 'quadratic'))\n","#     roc8_3 = np.append(roc8_3, auc)\n","#     fpr8_3 = np.append(fpr8_3, fpr)\n","\n","\n","\n","\n","  \n","########### stacking #######################\n","#### base models ####\n","    estimators8= [\n","      DecisionTreeClassifier(criterion=\"entropy\", max_features=\"auto\", splitter=\"best\"),\n","      SVC(C=2, gamma=\"auto\", kernel=\"rbf\", probability = True),\n","      GaussianNB(var_smoothing=6.579332246575682e-08),\n","      MLPClassifier(activation=\"relu\", learning_rate=\"invscaling\", solver=\"adam\"),\n","      GradientBoostingClassifier(learning_rate=0.1, n_estimators=100),\n","      LinearDiscriminantAnalysis(shrinkage=\"auto\", solver=\"eigen\"),\n","      LogisticRegression(C=2, multi_class=\"multinomial\", solver=\"newton-cg\"),\n","      RandomForestClassifier(criterion=\"gini\", max_depth=500, max_features=\"auto\", min_samples_leaf=1, min_samples_split=2, n_estimators=911)\n","      ]\n","\n","    estimators7= [\n","      DecisionTreeClassifier(criterion=\"entropy\", max_features=\"auto\", splitter=\"best\"),\n","      GaussianNB(var_smoothing=6.579332246575682e-08),\n","      MLPClassifier(activation=\"relu\", learning_rate=\"invscaling\", solver=\"adam\"),\n","      GradientBoostingClassifier(learning_rate=0.1, n_estimators=100),\n","      LinearDiscriminantAnalysis(shrinkage=\"auto\", solver=\"eigen\"),\n","      LogisticRegression(C=2, multi_class=\"multinomial\", solver=\"newton-cg\"),\n","      RandomForestClassifier(criterion=\"gini\", max_depth=500, max_features=\"auto\", min_samples_leaf=1, min_samples_split=2, n_estimators=911)\n","      ]\n","\n","    estimators6= [\n","      GaussianNB(var_smoothing=6.579332246575682e-08),\n","      MLPClassifier(activation=\"relu\", learning_rate=\"invscaling\", solver=\"adam\"),\n","      GradientBoostingClassifier(learning_rate=0.1, n_estimators=100),\n","      LinearDiscriminantAnalysis(shrinkage=\"auto\", solver=\"eigen\"),\n","      LogisticRegression(C=2, multi_class=\"multinomial\", solver=\"newton-cg\"),\n","      RandomForestClassifier(criterion=\"gini\", max_depth=500, max_features=\"auto\", min_samples_leaf=1, min_samples_split=2, n_estimators=911)\n","      ]\n","\n","    estimators5= [\n","      MLPClassifier(activation=\"relu\", learning_rate=\"invscaling\", solver=\"adam\"),\n","      GradientBoostingClassifier(learning_rate=0.1, n_estimators=100),\n","      LinearDiscriminantAnalysis(shrinkage=\"auto\", solver=\"eigen\"),\n","      GaussianNB(var_smoothing=6.579332246575682e-08),\n","      RandomForestClassifier(criterion=\"gini\", max_depth=500, max_features=\"auto\", min_samples_leaf=1, min_samples_split=2, n_estimators=911)\n","      ]\n","\n","    estimators4 = [\n","      MLPClassifier(activation=\"relu\", learning_rate=\"invscaling\", solver=\"adam\"),\n","      GradientBoostingClassifier(learning_rate=0.1, n_estimators=100),\n","      GaussianNB(var_smoothing=6.579332246575682e-08),\n","      RandomForestClassifier(criterion=\"gini\", max_depth=500, max_features=\"auto\", min_samples_leaf=1, min_samples_split=2, n_estimators=911)\n","      ]\n","\n","    estimators3 = [\n","      MLPClassifier(activation=\"relu\", learning_rate=\"invscaling\", solver=\"adam\"),\n","      GradientBoostingClassifier(learning_rate=0.1, n_estimators=100),\n","      RandomForestClassifier(criterion=\"gini\", max_depth=500, max_features=\"auto\", min_samples_leaf=1, min_samples_split=2, n_estimators=911)\n","      ]\n","\n","    estimators2 = [\n","      GradientBoostingClassifier(learning_rate=0.1, n_estimators=100),\n","      RandomForestClassifier(criterion=\"gini\", max_depth=500, max_features=\"auto\", min_samples_leaf=1, min_samples_split=2, n_estimators=911)\n","      ]\n","\n","    # sclf8 = StackingClassifier(estimators8, meta_classifier=LogisticRegression() )\n","    # sclf7 = StackingClassifier(estimators7, meta_classifier=LogisticRegression() )\n","    # sclf6 = StackingClassifier(estimators6, meta_classifier=LogisticRegression() )\n","    # sclf5 = StackingClassifier(estimators5, meta_classifier=LogisticRegression() )\n","    # sclf4 = StackingClassifier(estimators4, meta_classifier=LogisticRegression() )\n","    # sclf3 = StackingClassifier(estimators3, meta_classifier=LogisticRegression() )\n","    # sclf2 = StackingClassifier(estimators2, meta_classifier=LogisticRegression() )\n","\n","    # pipe1 = make_pipeline(FunctionTransformer(feature_1),\n","    #                       GradientBoostingClassifier(learning_rate=0.1, n_estimators=100))\n","    # pipe2 = make_pipeline(FunctionTransformer(feature_2),\n","    #                       RandomForestClassifier(criterion=\"gini\", max_depth=500, max_features=\"auto\", min_samples_leaf=1, min_samples_split=2, n_estimators=911))\n","    # pipe3 = make_pipeline(FunctionTransformer(feature_all),\n","    #                       MLPClassifier(activation=\"relu\", learning_rate=\"invscaling\", solver=\"adam\"))\n","    # pipe4 = make_pipeline(FunctionTransformer(feature_all),\n","    #                       GaussianNB(var_smoothing=6.579332246575682e-08))\n","    # pipe5 = make_pipeline(FunctionTransformer(feature_all),\n","    #                       LinearDiscriminantAnalysis(shrinkage=\"auto\", solver=\"eigen\"))\n","    # pipe6 = make_pipeline(FunctionTransformer(feature_all),\n","    #                       LogisticRegression(C=2, multi_class=\"multinomial\", solver=\"newton-cg\"))\n","    # pipe7 = make_pipeline(FunctionTransformer(feature_all),\n","    #                       DecisionTreeClassifier(criterion=\"entropy\", max_features=\"auto\", splitter=\"best\"))\n","    # pipe8 = make_pipeline(FunctionTransformer(feature_all),\n","    #                       SVC(C=2, gamma=\"auto\", kernel=\"rbf\", probability = True))\n","\n","                          \n","\n","    # sclf2 = StackingClassifier(classifiers=[pipe1, pipe2], \n","    #                           meta_classifier=LogisticRegression())\n","    # sclf3 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3], \n","    #                           meta_classifier=LogisticRegression())\n","    # sclf4 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4], \n","    #                           meta_classifier=LogisticRegression())\n","    # sclf5 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5], \n","    #                           meta_classifier=LogisticRegression())\n","    # sclf6 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5, pipe6], \n","    #                           meta_classifier=LogisticRegression())      \n","    # sclf7 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5, pipe6, pipe7], \n","    #                           meta_classifier=LogisticRegression())\n","    # sclf8 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5, pipe6, pipe8], \n","    #                           meta_classifier=LogisticRegression())\n","  \n","    # sclf2 = StackingClassifier(classifiers=[pipe1, pipe2], \n","    #                           meta_classifier=SVC(kernel='linear', probability=True))\n","    # sclf3 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3], \n","    #                           meta_classifier=SVC(kernel='linear', probability=True))\n","    # sclf4 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4], \n","    #                           meta_classifier=SVC(kernel='linear', probability=True))\n","    # sclf5 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5], \n","    #                           meta_classifier=SVC(kernel='linear', probability=True))\n","    # sclf6 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5, pipe6], \n","    #                           meta_classifier=SVC(kernel='linear', probability=True))      \n","    # sclf7 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5, pipe6, pipe7], \n","    #                           meta_classifier=SVC(kernel='linear', probability=True))\n","    # sclf8 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5, pipe6, pipe8], \n","    #                           meta_classifier=SVC(kernel='linear', probability=True))\n","\n","\n","    # sclf2 = StackingClassifier(classifiers=[pipe1, pipe2], \n","    #                           meta_classifier=DecisionTreeClassifier())\n","    # sclf3 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3], \n","    #                           meta_classifier=DecisionTreeClassifier())\n","    # sclf4 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4], \n","    #                           meta_classifier=DecisionTreeClassifier())\n","    # sclf5 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5], \n","    #                           meta_classifier=DecisionTreeClassifier())\n","    # sclf6 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5, pipe6], \n","    #                           meta_classifier=DecisionTreeClassifier())      \n","    # sclf7 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5, pipe6, pipe7], \n","    #                           meta_classifier=DecisionTreeClassifier())\n","    # sclf8 = StackingClassifier(classifiers=[pipe1, pipe2, pipe3, pipe4, pipe5, pipe6, pipe8], \n","    #                           meta_classifier=DecisionTreeClassifier())\n","    \n","    sclf8 = StackingClassifier(estimators8, meta_classifier=GradientBoostingClassifier() )\n","    sclf7 = StackingClassifier(estimators7, meta_classifier=GradientBoostingClassifier() )\n","    sclf6 = StackingClassifier(estimators6, meta_classifier=GradientBoostingClassifier() )\n","    sclf5 = StackingClassifier(estimators5, meta_classifier=GradientBoostingClassifier() )\n","    sclf4 = StackingClassifier(estimators4, meta_classifier=GradientBoostingClassifier() )\n","    sclf3 = StackingClassifier(estimators3, meta_classifier=GradientBoostingClassifier() )\n","    sclf2 = StackingClassifier(estimators2, meta_classifier=GradientBoostingClassifier() )\n","\n","    \n","    sclf2.fit(x_smote, y_smote)\n","    sclf3.fit(x_smote, y_smote)\n","    sclf4.fit(x_smote, y_smote)\n","    sclf5.fit(x_smote, y_smote)\n","    sclf6.fit(x_smote, y_smote)\n","    sclf7.fit(x_smote, y_smote)\n","    sclf8.fit(x_smote, y_smote)\n","\n","\n","########\n","    probs_stacking2 = sclf2.predict_proba(test_x)\n","    probs_stacking2 = probs_stacking2[:, 1]\n","    pred_stacking2 = (probs_stacking2 >= 0.5).astype(bool) \n","    f1_stacking2 = f1_score(test_y, pred_stacking2)\n","\n","    tn, fp, fn, tp = confusion_matrix(test_y, pred_stacking2).ravel()\n","    fpr = (fp)/(fp+tn)\n","    auc = roc_auc_score(test_y, probs_stacking2)\n","    fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","    tot_n =  tn+fp+fn+tp\n","    real_cheaters = tp+fn\n","\n","    #### write to excel sheet ####\n","    sheet.write(25, 0, \"stacking2\")\n","    sheet.write(25, 1, \"\")\n","    sheet.write(25, 2, \"0.5\")\n","    sheet.write(25, 3, precision_score(test_y, pred_stacking2))\n","    sheet.write(25, 4, recall_score(test_y, pred_stacking2))\n","    sheet.write(25, 5, f1_stacking2)\n","    sheet.write(25, 6, cohen_kappa_score(test_y, pred_stacking2, weights = 'quadratic'))\n","    sheet.write(25, 7, auc)\n","    sheet.write(25, 8, fpr)\n","    sheet.write(25, 9, str(tp))\n","    sheet.write(25, 10, str(fn))\n","    sheet.write(25, 11, str(fp))\n","    sheet.write(25, 12, str(tn))\n","    sheet.write(25, 13, str(tot_n))\n","    sheet.write(25, 14, str(fptp_rate))\n","    sheet.write(25, 15, str(real_cheaters))\n","    sheet.write(25, 16, str(size_trainset))\n","\n","    precision_s2 = np.append(precision_s2, precision_score(test_y, pred_stacking2))\n","    recall_s2 = np.append(recall_s2, recall_score(test_y, pred_stacking2))\n","    f1_s2 = np.append(f1_s2, f1_stacking2)\n","    kappa_s2 = np.append(kappa_s2, cohen_kappa_score(test_y, pred_stacking2, weights = 'quadratic'))\n","    roc_s2 = np.append(roc_s2, auc)\n","    fpr_s2 = np.append(fpr_s2, fpr)\n","\n","\n","##########\n","    probs_stacking3 = sclf3.predict_proba(test_x)\n","    probs_stacking3 = probs_stacking3[:, 1]\n","    pred_stacking3 = (probs_stacking3 >= 0.5).astype(bool) \n","    f1_stacking3 = f1_score(test_y, pred_stacking3)\n","\n","    tn, fp, fn, tp = confusion_matrix(test_y, pred_stacking3).ravel()\n","    fpr = (fp)/(fp+tn)\n","    auc = roc_auc_score(test_y, probs_stacking3)\n","    fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","    tot_n =  tn+fp+fn+tp\n","    real_cheaters = tp+fn\n","\n","    #### write to excel sheet ####\n","    sheet.write(26, 0, \"stacking3\")\n","    sheet.write(26, 1, \"\")\n","    sheet.write(26, 2, \"0.5\")\n","    sheet.write(26, 3, precision_score(test_y, pred_stacking3))\n","    sheet.write(26, 4, recall_score(test_y, pred_stacking3))\n","    sheet.write(26, 5, f1_stacking3)\n","    sheet.write(26, 6, cohen_kappa_score(test_y, pred_stacking3, weights = 'quadratic'))\n","    sheet.write(26, 7, auc)\n","    sheet.write(26, 8, fpr)\n","    sheet.write(26, 9, str(tp))\n","    sheet.write(26, 10, str(fn))\n","    sheet.write(26, 11, str(fp))\n","    sheet.write(26, 12, str(tn))\n","    sheet.write(26, 13, str(tot_n))\n","    sheet.write(26, 14, str(fptp_rate))\n","    sheet.write(26, 15, str(real_cheaters))\n","    sheet.write(26, 16, str(size_trainset))\n","\n","    precision_s3 = np.append(precision_s3, precision_score(test_y, pred_stacking3))\n","    recall_s3 = np.append(recall_s3, recall_score(test_y, pred_stacking3))\n","    f1_s3 = np.append(f1_s3, f1_stacking3)\n","    kappa_s3 = np.append(kappa_s3, cohen_kappa_score(test_y, pred_stacking3, weights = 'quadratic'))\n","    roc_s3 = np.append(roc_s3, auc)\n","    fpr_s3 = np.append(fpr_s3, fpr)\n","\n","#########\n","    probs_stacking4 = sclf4.predict_proba(test_x)\n","    probs_stacking4 = probs_stacking4[:, 1]\n","    pred_stacking4 = (probs_stacking4 >= 0.5).astype(bool) \n","    f1_stacking4 = f1_score(test_y, pred_stacking4)\n","\n","    tn, fp, fn, tp = confusion_matrix(test_y, pred_stacking4).ravel()\n","    fpr = (fp)/(fp+tn)\n","    auc = roc_auc_score(test_y, probs_stacking4)\n","    fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","    tot_n =  tn+fp+fn+tp\n","    real_cheaters = tp+fn\n","\n","    #### write to excel sheet ####\n","    sheet.write(27, 0, \"stacking4\")\n","    sheet.write(27, 1, \"\")\n","    sheet.write(27, 2, \"0.5\")\n","    sheet.write(27, 3, precision_score(test_y, pred_stacking4))\n","    sheet.write(27, 4, recall_score(test_y, pred_stacking4))\n","    sheet.write(27, 5, f1_stacking4)\n","    sheet.write(27, 6, cohen_kappa_score(test_y, pred_stacking4, weights = 'quadratic'))\n","    sheet.write(27, 7, auc)\n","    sheet.write(27, 8, fpr)\n","    sheet.write(27, 9, str(tp))\n","    sheet.write(27, 10, str(fn))\n","    sheet.write(27, 11, str(fp))\n","    sheet.write(27, 12, str(tn))\n","    sheet.write(27, 13, str(tot_n))\n","    sheet.write(27, 14, str(fptp_rate))\n","    sheet.write(27, 15, str(real_cheaters))\n","    sheet.write(27, 16, str(size_trainset))\n","\n","    precision_s4 = np.append(precision_s4, precision_score(test_y, pred_stacking4))\n","    recall_s4 = np.append(recall_s4, recall_score(test_y, pred_stacking4))\n","    f1_s4 = np.append(f1_s4, f1_stacking4)\n","    kappa_s4 = np.append(kappa_s4, cohen_kappa_score(test_y, pred_stacking4, weights = 'quadratic'))\n","    roc_s4 = np.append(roc_s4, auc)\n","    fpr_s4 = np.append(fpr_s4, fpr)\n","\n","#########\n","    probs_stacking5 = sclf5.predict_proba(test_x)\n","    probs_stacking5 = probs_stacking5[:, 1]\n","    pred_stacking5 = (probs_stacking5 >= 0.5).astype(bool) \n","    f1_stacking5 = f1_score(test_y, pred_stacking5)\n","\n","    tn, fp, fn, tp = confusion_matrix(test_y, pred_stacking5).ravel()\n","    fpr = (fp)/(fp+tn)\n","    auc = roc_auc_score(test_y, probs_stacking5)\n","    fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","    tot_n =  tn+fp+fn+tp\n","    real_cheaters = tp+fn\n","\n","    #### write to excel sheet ####\n","    sheet.write(28, 0, \"stacking5\")\n","    sheet.write(28, 1, \"\")\n","    sheet.write(28, 2, \"0.5\")\n","    sheet.write(28, 3, precision_score(test_y, pred_stacking5))\n","    sheet.write(28, 4, recall_score(test_y, pred_stacking5))\n","    sheet.write(28, 5, f1_stacking5)\n","    sheet.write(28, 6, cohen_kappa_score(test_y, pred_stacking5, weights = 'quadratic'))\n","    sheet.write(28, 7, auc)\n","    sheet.write(28, 8, fpr)\n","    sheet.write(28, 9, str(tp))\n","    sheet.write(28, 10, str(fn))\n","    sheet.write(28, 11, str(fp))\n","    sheet.write(28, 12, str(tn))\n","    sheet.write(28, 13, str(tot_n))\n","    sheet.write(28, 14, str(fptp_rate))\n","    sheet.write(28, 15, str(real_cheaters))\n","    sheet.write(28, 16, str(size_trainset))\n","\n","    precision_s5 = np.append(precision_s5, precision_score(test_y, pred_stacking5))\n","    recall_s5 = np.append(recall_s5, recall_score(test_y, pred_stacking5))\n","    f1_s5 = np.append(f1_s5, f1_stacking5)\n","    kappa_s5 = np.append(kappa_s5, cohen_kappa_score(test_y, pred_stacking5, weights = 'quadratic'))\n","    roc_s5 = np.append(roc_s5, auc)\n","    fpr_s5 = np.append(fpr_s5, fpr)\n","\n","#########\n","    probs_stacking6 = sclf6.predict_proba(test_x)\n","    probs_stacking6 = probs_stacking6[:, 1]\n","    pred_stacking6 = (probs_stacking6 >= 0.5).astype(bool) \n","    f1_stacking6 = f1_score(test_y, pred_stacking6)\n","\n","    tn, fp, fn, tp = confusion_matrix(test_y, pred_stacking6).ravel()\n","    fpr = (fp)/(fp+tn)\n","    auc = roc_auc_score(test_y, probs_stacking6)\n","    fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","    tot_n =  tn+fp+fn+tp\n","    real_cheaters = tp+fn\n","\n","    #### write to excel sheet ####\n","    sheet.write(29, 0, \"stacking6\")\n","    sheet.write(29, 1, \"\")\n","    sheet.write(29, 2, \"0.5\")\n","    sheet.write(29, 3, precision_score(test_y, pred_stacking6))\n","    sheet.write(29, 4, recall_score(test_y, pred_stacking6))\n","    sheet.write(29, 5, f1_stacking6)\n","    sheet.write(29, 6, cohen_kappa_score(test_y, pred_stacking6, weights = 'quadratic'))\n","    sheet.write(29, 7, auc)\n","    sheet.write(29, 8, fpr)\n","    sheet.write(29, 9, str(tp))\n","    sheet.write(29, 10, str(fn))\n","    sheet.write(29, 11, str(fp))\n","    sheet.write(29, 12, str(tn))\n","    sheet.write(29, 13, str(tot_n))\n","    sheet.write(29, 14, str(fptp_rate))\n","    sheet.write(29, 15, str(real_cheaters))\n","    sheet.write(29, 16, str(size_trainset))\n","\n","    precision_s6 = np.append(precision_s6, precision_score(test_y, pred_stacking6))\n","    recall_s6 = np.append(recall_s6, recall_score(test_y, pred_stacking6))\n","    f1_s6 = np.append(f1_s6, f1_stacking6)\n","    kappa_s6 = np.append(kappa_s6, cohen_kappa_score(test_y, pred_stacking6, weights = 'quadratic'))\n","    roc_s6 = np.append(roc_s6, auc)\n","    fpr_s6 = np.append(fpr_s6, fpr)\n","\n","#########\n","    probs_stacking7 = sclf7.predict_proba(test_x)\n","    probs_stacking7 = probs_stacking7[:, 1]\n","    pred_stacking7 = (probs_stacking7 >= 0.5).astype(bool) \n","    f1_stacking7 = f1_score(test_y, pred_stacking7)\n","\n","    tn, fp, fn, tp = confusion_matrix(test_y, pred_stacking7).ravel()\n","    fpr = (fp)/(fp+tn)\n","    auc = roc_auc_score(test_y, probs_stacking7)\n","    fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","    tot_n =  tn+fp+fn+tp\n","    real_cheaters = tp+fn\n","\n","    #### write to excel sheet ####\n","    sheet.write(30, 0, \"stacking7\")\n","    sheet.write(30, 1, \"\")\n","    sheet.write(30, 2, \"0.5\")\n","    sheet.write(30, 3, precision_score(test_y, pred_stacking7))\n","    sheet.write(30, 4, recall_score(test_y, pred_stacking7))\n","    sheet.write(30, 5, f1_stacking7)\n","    sheet.write(30, 6, cohen_kappa_score(test_y, pred_stacking7, weights = 'quadratic'))\n","    sheet.write(30, 7, auc)\n","    sheet.write(30, 8, fpr)\n","    sheet.write(30, 9, str(tp))\n","    sheet.write(30, 10, str(fn))\n","    sheet.write(30, 11, str(fp))\n","    sheet.write(30, 12, str(tn))\n","    sheet.write(30, 13, str(tot_n))\n","    sheet.write(30, 14, str(fptp_rate))\n","    sheet.write(30, 15, str(real_cheaters))\n","    sheet.write(30, 16, str(size_trainset))\n","\n","    precision_s7 = np.append(precision_s7, precision_score(test_y, pred_stacking7))\n","    recall_s7 = np.append(recall_s7, recall_score(test_y, pred_stacking7))\n","    f1_s7 = np.append(f1_s7, f1_stacking7)\n","    kappa_s7 = np.append(kappa_s7, cohen_kappa_score(test_y, pred_stacking7, weights = 'quadratic'))\n","    roc_s7 = np.append(roc_s7, auc)\n","    fpr_s7 = np.append(fpr_s7, fpr)\n","\n","#########\n","    probs_stacking8 = sclf8.predict_proba(test_x)\n","    probs_stacking8 = probs_stacking8[:, 1]\n","    pred_stacking8 = (probs_stacking8 >= 0.5).astype(bool) \n","    f1_stacking8 = f1_score(test_y, pred_stacking8)\n","\n","    tn, fp, fn, tp = confusion_matrix(test_y, pred_stacking8).ravel()\n","    fpr = (fp)/(fp+tn)\n","    auc = roc_auc_score(test_y, probs_stacking8)\n","    fptp_rate = (fp+tp)/(tn+fp+fn+tp)\n","    tot_n =  tn+fp+fn+tp\n","    real_cheaters = tp+fn\n","\n","    #### write to excel sheet ####\n","    sheet.write(31, 0, \"stacking8\")\n","    sheet.write(31, 1, \"\")\n","    sheet.write(31, 2, \"0.5\")\n","    sheet.write(31, 3, precision_score(test_y, pred_stacking8))\n","    sheet.write(31, 4, recall_score(test_y, pred_stacking8))\n","    sheet.write(31, 5, f1_stacking8)\n","    sheet.write(31, 6, cohen_kappa_score(test_y, pred_stacking8, weights = 'quadratic'))\n","    sheet.write(31, 7, auc)\n","    sheet.write(31, 8, fpr)\n","    sheet.write(31, 9, str(tp))\n","    sheet.write(31, 10, str(fn))\n","    sheet.write(31, 11, str(fp))\n","    sheet.write(31, 12, str(tn))\n","    sheet.write(31, 13, str(tot_n))\n","    sheet.write(31, 14, str(fptp_rate))\n","    sheet.write(31, 15, str(real_cheaters))\n","    sheet.write(31, 16, str(size_trainset))\n","\n","    precision_s8 = np.append(precision_s8, precision_score(test_y, pred_stacking8))\n","    recall_s8 = np.append(recall_s8, recall_score(test_y, pred_stacking8))\n","    f1_s8 = np.append(f1_s8, f1_stacking8)\n","    kappa_s8 = np.append(kappa_s8, cohen_kappa_score(test_y, pred_stacking8, weights = 'quadratic'))\n","    roc_s8 = np.append(roc_s8, auc)\n","    fpr_s8 = np.append(fpr_s8, fpr)\n","\n","############\n","sheet_mean = wb.add_sheet('mean', cell_overwrite_ok=True) \n","\n","sheet_mean.write(0, 0, 'Model')\n","sheet_mean.write(0, 1, 'dataset')\n","sheet_mean.write(0, 2, 'threshold')\n","sheet_mean.write(0, 3, 'Precision')\n","sheet_mean.write(0, 4, 'Recall')\n","sheet_mean.write(0, 5, 'F1 Score')\n","sheet_mean.write(0, 6, 'weighted Kappa')\n","sheet_mean.write(0, 7, 'ROC AUC')\n","sheet_mean.write(0, 8, 'FPR')\n","\n","# sheet_mean.write(1, 0, \"Decision Tree\")\n","# sheet_mean.write(1, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(1, 2, \"0.7\")\n","# sheet_mean.write(1, 3, np.mean(precision1_1))\n","# sheet_mean.write(1, 4, np.mean(recall1_1))\n","# sheet_mean.write(1, 5, np.mean(f1_score1_1))\n","# sheet_mean.write(1, 6, np.mean(kappa1_1))\n","# sheet_mean.write(1, 7, np.mean(roc1_1))\n","# sheet_mean.write(1, 8, np.mean(fpr1_1))\n","\n","# sheet_mean.write(2, 0, \"Decision Tree\")\n","# sheet_mean.write(2, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(2, 2, \"0.5\")\n","# sheet_mean.write(2, 3, np.mean(precision1_2))\n","# sheet_mean.write(2, 4, np.mean(recall1_2))\n","# sheet_mean.write(2, 5, np.mean(f1_score1_2))\n","# sheet_mean.write(2, 6, np.mean(kappa1_2))\n","# sheet_mean.write(2, 7, np.mean(roc1_2))\n","# sheet_mean.write(2, 8, np.mean(fpr1_2))\n","\n","# sheet_mean.write(3, 0, \"Decision Tree\")\n","# sheet_mean.write(3, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(3, 2, \"0.97\")\n","# sheet_mean.write(3, 3, np.mean(precision1_3))\n","# sheet_mean.write(3, 4, np.mean(recall1_3))\n","# sheet_mean.write(3, 5, np.mean(f1_score1_3))\n","# sheet_mean.write(3, 6, np.mean(kappa1_3))\n","# sheet_mean.write(3, 7, np.mean(roc1_3))\n","# sheet_mean.write(3, 8, np.mean(fpr1_3))\n","\n","\n","# ###########\n","# sheet_mean.write(4, 0, \"Support Vector Machine\")\n","# sheet_mean.write(4, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(4, 2, \"0.7\")\n","# sheet_mean.write(4, 3, np.mean(precision2_1))\n","# sheet_mean.write(4, 4, np.mean(recall2_1))\n","# sheet_mean.write(4, 5, np.mean(f1_score2_1))\n","# sheet_mean.write(4, 6, np.mean(kappa2_1))\n","# sheet_mean.write(4, 7, np.mean(roc2_1))\n","# sheet_mean.write(4, 8, np.mean(fpr2_1))\n","\n","# sheet_mean.write(5, 0, \"Support Vector Machine\")\n","# sheet_mean.write(5, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(5, 2, \"0.5\")\n","# sheet_mean.write(5, 3, np.mean(precision2_2))\n","# sheet_mean.write(5, 4, np.mean(recall2_2))\n","# sheet_mean.write(5, 5, np.mean(f1_score2_2))\n","# sheet_mean.write(5, 6, np.mean(kappa2_2))\n","# sheet_mean.write(5, 7, np.mean(roc2_2))\n","# sheet_mean.write(5, 8, np.mean(fpr2_2))\n","\n","# sheet_mean.write(6, 0, \"Support Vector Machine\")\n","# sheet_mean.write(6, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(6, 2, \"0.97\")\n","# sheet_mean.write(6, 3, np.mean(precision2_3))\n","# sheet_mean.write(6, 4, np.mean(recall2_3))\n","# sheet_mean.write(6, 5, np.mean(f1_score2_3))\n","# sheet_mean.write(6, 6, np.mean(kappa2_3))\n","# sheet_mean.write(6, 7, np.mean(roc2_3))\n","# sheet_mean.write(6, 8, np.mean(fpr2_3))\n","\n","\n","# ######################\n","# sheet_mean.write(7, 0, \"Logistic Regression\")\n","# sheet_mean.write(7, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(7, 2, \"0.7\")\n","# sheet_mean.write(7, 3, np.mean(precision3_1))\n","# sheet_mean.write(7, 4, np.mean(recall3_1))\n","# sheet_mean.write(7, 5, np.mean(f1_score3_1))\n","# sheet_mean.write(7, 6, np.mean(kappa3_1))\n","# sheet_mean.write(7, 7, np.mean(roc3_1))\n","# sheet_mean.write(7, 8, np.mean(fpr3_1))\n","\n","# sheet_mean.write(8, 0, \"Logistic Regression\")\n","# sheet_mean.write(8, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(8, 2, \"0.5\")\n","# sheet_mean.write(8, 3, np.mean(precision3_2))\n","# sheet_mean.write(8, 4, np.mean(recall3_2))\n","# sheet_mean.write(8, 5, np.mean(f1_score3_2))\n","# sheet_mean.write(8, 6, np.mean(kappa3_2))\n","# sheet_mean.write(8, 7, np.mean(roc3_2))\n","# sheet_mean.write(8, 8, np.mean(fpr3_2))\n","\n","# sheet_mean.write(9, 0, \"Logistic Regression\")\n","# sheet_mean.write(9, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(9, 2, \"0.97\")\n","# sheet_mean.write(9, 3, np.mean(precision3_3))\n","# sheet_mean.write(9, 4, np.mean(recall3_3))\n","# sheet_mean.write(9, 5, np.mean(f1_score3_3))\n","# sheet_mean.write(9, 6, np.mean(kappa3_3))\n","# sheet_mean.write(9, 7, np.mean(roc3_3))\n","# sheet_mean.write(9, 8, np.mean(fpr3_3))\n","\n","\n","# ##################################\n","# sheet_mean.write(10, 0, \"Discriminant Analysis\")\n","# sheet_mean.write(10, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(10, 2, \"0.7\")\n","# sheet_mean.write(10, 3, np.mean(precision4_1))\n","# sheet_mean.write(10, 4, np.mean(recall4_1))\n","# sheet_mean.write(10, 5, np.mean(f1_score4_1))\n","# sheet_mean.write(10, 6, np.mean(kappa4_1))\n","# sheet_mean.write(10, 7, np.mean(roc4_1))\n","# sheet_mean.write(10, 8, np.mean(fpr4_1))\n","\n","# sheet_mean.write(11, 0, \"Discriminant Analysis\")\n","# sheet_mean.write(11, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(11, 2, \"0.5\")\n","# sheet_mean.write(11, 3, np.mean(precision4_2))\n","# sheet_mean.write(11, 4, np.mean(recall4_2))\n","# sheet_mean.write(11, 5, np.mean(f1_score4_2))\n","# sheet_mean.write(11, 6, np.mean(kappa4_2))\n","# sheet_mean.write(11, 7, np.mean(roc4_2))\n","# sheet_mean.write(11, 8, np.mean(fpr4_2))\n","\n","# sheet_mean.write(12, 0, \"Discriminant Analysis\")\n","# sheet_mean.write(12, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(12, 2, \"0.97\")\n","# sheet_mean.write(12, 3, np.mean(precision4_3))\n","# sheet_mean.write(12, 4, np.mean(recall4_3))\n","# sheet_mean.write(12, 5, np.mean(f1_score4_3))\n","# sheet_mean.write(12, 6, np.mean(kappa4_3))\n","# sheet_mean.write(12, 7, np.mean(roc4_3))\n","# sheet_mean.write(12, 8, np.mean(fpr4_3))\n","\n","\n","\n","# #####################################\n","# sheet_mean.write(13, 0, \"Naive Bayes\")\n","# sheet_mean.write(13, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(13, 2, \"0.7\")\n","# sheet_mean.write(13, 3, np.mean(precision5_1))\n","# sheet_mean.write(13, 4, np.mean(recall5_1))\n","# sheet_mean.write(13, 5, np.mean(f1_score5_1))\n","# sheet_mean.write(13, 6, np.mean(kappa5_1))\n","# sheet_mean.write(13, 7, np.mean(roc5_1))\n","# sheet_mean.write(13, 8, np.mean(fpr5_1))\n","\n","# sheet_mean.write(14, 0, \"Naive Bayes\")\n","# sheet_mean.write(14, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(14, 2, \"0.5\")\n","# sheet_mean.write(14, 3, np.mean(precision5_2))\n","# sheet_mean.write(14, 4, np.mean(recall5_2))\n","# sheet_mean.write(14, 5, np.mean(f1_score5_2))\n","# sheet_mean.write(14, 6, np.mean(kappa5_2))\n","# sheet_mean.write(14, 7, np.mean(roc5_2))\n","# sheet_mean.write(14, 8, np.mean(fpr5_2))\n","\n","# sheet_mean.write(15, 0, \"Naive Bayes\")\n","# sheet_mean.write(15, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(15, 2, \"0.97\")\n","# sheet_mean.write(15, 3, np.mean(precision5_3))\n","# sheet_mean.write(15, 4, np.mean(recall5_3))\n","# sheet_mean.write(15, 5, np.mean(f1_score5_3))\n","# sheet_mean.write(15, 6, np.mean(kappa5_3))\n","# sheet_mean.write(15, 7, np.mean(roc5_3))\n","# sheet_mean.write(15, 8, np.mean(fpr5_3))\n","\n","\n","# #########################################\n","# sheet_mean.write(16, 0, \"Neural Network\")\n","# sheet_mean.write(16, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(16, 2, \"0.7\")\n","# sheet_mean.write(16, 3, np.mean(precision6_1))\n","# sheet_mean.write(16, 4, np.mean(recall6_1))\n","# sheet_mean.write(16, 5, np.mean(f1_score6_1))\n","# sheet_mean.write(16, 6, np.mean(kappa6_1))\n","# sheet_mean.write(16, 7, np.mean(roc6_1))\n","# sheet_mean.write(16, 8, np.mean(fpr6_1))\n","\n","# sheet_mean.write(17, 0, \"Neural Network\")\n","# sheet_mean.write(17, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(17, 2, \"0.5\")\n","# sheet_mean.write(17, 3, np.mean(precision6_2))\n","# sheet_mean.write(17, 4, np.mean(recall6_2))\n","# sheet_mean.write(17, 5, np.mean(f1_score6_2))\n","# sheet_mean.write(17, 6, np.mean(kappa6_2))\n","# sheet_mean.write(17, 7, np.mean(roc6_2))\n","# sheet_mean.write(17, 8, np.mean(fpr6_2))\n","\n","# sheet_mean.write(18, 0, \"Neural Network\")\n","# sheet_mean.write(18, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(18, 2, \"0.97\")\n","# sheet_mean.write(18, 3, np.mean(precision6_3))\n","# sheet_mean.write(18, 4, np.mean(recall6_3))\n","# sheet_mean.write(18, 5, np.mean(f1_score6_3))\n","# sheet_mean.write(18, 6, np.mean(kappa6_3))\n","# sheet_mean.write(18, 7, np.mean(roc6_3))\n","# sheet_mean.write(18, 8, np.mean(fpr6_3))\n","\n","\n","# #####################################\n","# sheet_mean.write(19, 0, \"Random Forest\")\n","# sheet_mean.write(19, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(19, 2, \"0.7\")\n","# sheet_mean.write(19, 3, np.mean(precision7_1))\n","# sheet_mean.write(19, 4, np.mean(recall7_1))\n","# sheet_mean.write(19, 5, np.mean(f1_score7_1))\n","# sheet_mean.write(19, 6, np.mean(kappa7_1))\n","# sheet_mean.write(19, 7, np.mean(roc7_1))\n","# sheet_mean.write(19, 8, np.mean(fpr7_1))\n","\n","# sheet_mean.write(20, 0, \"Random Forest\")\n","# sheet_mean.write(20, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(20, 2, \"0.5\")\n","# sheet_mean.write(20, 3, np.mean(precision7_2))\n","# sheet_mean.write(20, 4, np.mean(recall7_2))\n","# sheet_mean.write(20, 5, np.mean(f1_score7_2))\n","# sheet_mean.write(20, 6, np.mean(kappa7_2))\n","# sheet_mean.write(20, 7, np.mean(roc7_2))\n","# sheet_mean.write(20, 8, np.mean(fpr7_2))\n","\n","# sheet_mean.write(21, 0, \"Random Forest\")\n","# sheet_mean.write(21, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(21, 2, \"0.97\")\n","# sheet_mean.write(21, 3, np.mean(precision7_3))\n","# sheet_mean.write(21, 4, np.mean(recall7_3))\n","# sheet_mean.write(21, 5, np.mean(f1_score7_3))\n","# sheet_mean.write(21, 6, np.mean(kappa7_3))\n","# sheet_mean.write(21, 7, np.mean(roc7_3))\n","# sheet_mean.write(21, 8, np.mean(fpr7_3))\n","\n","\n","# ####################################\n","# sheet_mean.write(22, 0, \"Gradient Boosting\")\n","# sheet_mean.write(22, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(22, 2, \"0.7\")\n","# sheet_mean.write(22, 3, np.mean(precision8_1))\n","# sheet_mean.write(22, 4, np.mean(recall8_1))\n","# sheet_mean.write(22, 5, np.mean(f1_score8_1))\n","# sheet_mean.write(22, 6, np.mean(kappa8_1))\n","# sheet_mean.write(22, 7, np.mean(roc8_1))\n","# sheet_mean.write(22, 8, np.mean(fpr8_1))\n","\n","# sheet_mean.write(23, 0, \"Gradient Boosting\")\n","# sheet_mean.write(23, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(23, 2, \"0.5\")\n","# sheet_mean.write(23, 3, np.mean(precision8_2))\n","# sheet_mean.write(23, 4, np.mean(recall8_2))\n","# sheet_mean.write(23, 5, np.mean(f1_score8_2))\n","# sheet_mean.write(23, 6, np.mean(kappa8_2))\n","# sheet_mean.write(23, 7, np.mean(roc8_2))\n","# sheet_mean.write(23, 8, np.mean(fpr8_2))\n","\n","# sheet_mean.write(24, 0, \"Gradient Boosting\")\n","# sheet_mean.write(24, 1, \"iraw_idur_OEF\")\n","# sheet_mean.write(24, 2, \"0.97\")\n","# sheet_mean.write(24, 3, np.mean(precision8_3))\n","# sheet_mean.write(24, 4, np.mean(recall8_3))\n","# sheet_mean.write(24, 5, np.mean(f1_score8_3))\n","# sheet_mean.write(24, 6, np.mean(kappa8_3))\n","# sheet_mean.write(24, 7, np.mean(roc8_3))\n","# sheet_mean.write(24, 8, np.mean(fpr8_3))\n","\n","sheet_mean.write(25, 0, \"stacking2\")\n","sheet_mean.write(25, 1, \"\")\n","sheet_mean.write(25, 2, \"0.5\")\n","sheet_mean.write(25, 3, np.mean(precision_s2))\n","sheet_mean.write(25, 4, np.mean(recall_s2))\n","sheet_mean.write(25, 5, np.mean(f1_s2))\n","sheet_mean.write(25, 6, np.mean(kappa_s2))\n","sheet_mean.write(25, 7, np.mean(roc_s2))\n","sheet_mean.write(25, 8, np.mean(fpr_s2))\n","\n","sheet_mean.write(26, 0, \"stacking3\")\n","sheet_mean.write(26, 1, \"\")\n","sheet_mean.write(26, 2, \"0.5\")\n","sheet_mean.write(26, 3, np.mean(precision_s3))\n","sheet_mean.write(26, 4, np.mean(recall_s3))\n","sheet_mean.write(26, 5, np.mean(f1_s3))\n","sheet_mean.write(26, 6, np.mean(kappa_s3))\n","sheet_mean.write(26, 7, np.mean(roc_s3))\n","sheet_mean.write(26, 8, np.mean(fpr_s3))\n","\n","sheet_mean.write(27, 0, \"stacking4\")\n","sheet_mean.write(27, 1, \"\")\n","sheet_mean.write(27, 2, \"0.5\")\n","sheet_mean.write(27, 3, np.mean(precision_s4))\n","sheet_mean.write(27, 4, np.mean(recall_s4))\n","sheet_mean.write(27, 5, np.mean(f1_s4))\n","sheet_mean.write(27, 6, np.mean(kappa_s4))\n","sheet_mean.write(27, 7, np.mean(roc_s4))\n","sheet_mean.write(27, 8, np.mean(fpr_s4))\n","\n","sheet_mean.write(28, 0, \"stacking5\")\n","sheet_mean.write(28, 1, \"\")\n","sheet_mean.write(28, 2, \"0.5\")\n","sheet_mean.write(28, 3, np.mean(precision_s5))\n","sheet_mean.write(28, 4, np.mean(recall_s5))\n","sheet_mean.write(28, 5, np.mean(f1_s5))\n","sheet_mean.write(28, 6, np.mean(kappa_s5))\n","sheet_mean.write(28, 7, np.mean(roc_s5))\n","sheet_mean.write(28, 8, np.mean(fpr_s5))\n","\n","sheet_mean.write(29, 0, \"stacking6\")\n","sheet_mean.write(29, 1, \"\")\n","sheet_mean.write(29, 2, \"0.5\")\n","sheet_mean.write(29, 3, np.mean(precision_s6))\n","sheet_mean.write(29, 4, np.mean(recall_s6))\n","sheet_mean.write(29, 5, np.mean(f1_s6))\n","sheet_mean.write(29, 6, np.mean(kappa_s6))\n","sheet_mean.write(29, 7, np.mean(roc_s6))\n","sheet_mean.write(29, 8, np.mean(fpr_s6))\n","\n","sheet_mean.write(30, 0, \"stacking7\")\n","sheet_mean.write(30, 1, \"\")\n","sheet_mean.write(30, 2, \"0.5\")\n","sheet_mean.write(30, 3, np.mean(precision_s7))\n","sheet_mean.write(30, 4, np.mean(recall_s7))\n","sheet_mean.write(30, 5, np.mean(f1_s7))\n","sheet_mean.write(30, 6, np.mean(kappa_s7))\n","sheet_mean.write(30, 7, np.mean(roc_s7))\n","sheet_mean.write(30, 8, np.mean(fpr_s7))\n","\n","sheet_mean.write(31, 0, \"stacking8\")\n","sheet_mean.write(31, 1, \"\")\n","sheet_mean.write(31, 2, \"0.5\")\n","sheet_mean.write(31, 3, np.mean(precision_s8))\n","sheet_mean.write(31, 4, np.mean(recall_s8))\n","sheet_mean.write(31, 5, np.mean(f1_s8))\n","sheet_mean.write(31, 6, np.mean(kappa_s8))\n","sheet_mean.write(31, 7, np.mean(roc_s8))\n","sheet_mean.write(31, 8, np.mean(fpr_s8))\n"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n"]}]},{"cell_type":"code","source":["wb.save('1form_both50_04_seed25_top10features_gb.xls') "],"metadata":{"id":"3hoYtMCZZQ7h","executionInfo":{"status":"ok","timestamp":1645569039454,"user_tz":300,"elapsed":14,"user":{"displayName":"Todd Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17241037338912296053"}}},"execution_count":28,"outputs":[]}]}